travis_fold:start:system_info[0K[33;1mBuild system information[0m
Build language: java
Build group: stable
Build dist: trusty
Build id: ''
Job id: ''
[34m[1mBuild image provisioning date and time[0m
Tue Dec  5 20:11:19 UTC 2017
[34m[1mOperating System Details[0m
Distributor ID:	Ubuntu
Description:	Ubuntu 14.04.5 LTS
Release:	14.04
Codename:	trusty
[34m[1mCookbooks Version[0m
7c2c6a6 https://github.com/travis-ci/travis-cookbooks/tree/7c2c6a6
[34m[1mgit version[0m
git version 2.15.1
[34m[1mbash version[0m
GNU bash, version 4.3.11(1)-release (x86_64-pc-linux-gnu)
[34m[1mgcc version[0m
gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[34m[1mdocker version[0m
Client:
 Version:      17.09.0-ce
 API version:  1.32
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:39:28 2017
 OS/Arch:      linux/amd64
[34m[1mclang version[0m
clang version 5.0.0 (tags/RELEASE_500/final)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/local/clang-5.0.0/bin
[34m[1mjq version[0m
jq-1.5
[34m[1mbats version[0m
Bats 0.4.0
[34m[1mshellcheck version[0m
0.4.6
[34m[1mshfmt version[0m
v2.0.0
[34m[1mccache version[0m
ccache version 3.1.9

Copyright (C) 2002-2007 Andrew Tridgell
Copyright (C) 2009-2011 Joel Rosdahl

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; either version 3 of the License, or (at your option) any later
version.
[34m[1mcmake version[0m
cmake version 3.9.2

CMake suite maintained and supported by Kitware (kitware.com/cmake).
[34m[1mheroku version[0m
heroku-cli/6.14.39-addc925 (linux-x64) node-v9.2.0
[34m[1mimagemagick version[0m
Version: ImageMagick 6.7.7-10 2017-07-31 Q16 http://www.imagemagick.org
[34m[1mmd5deep version[0m
4.2
[34m[1mmercurial version[0m
Mercurial Distributed SCM (version 4.2.2)
(see https://mercurial-scm.org for more information)

Copyright (C) 2005-2017 Matt Mackall and others
This is free software; see the source for copying conditions. There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
[34m[1mmysql version[0m
mysql  Ver 14.14 Distrib 5.6.33, for debian-linux-gnu (x86_64) using  EditLine wrapper
[34m[1mopenssl version[0m
OpenSSL 1.0.1f 6 Jan 2014
[34m[1mpacker version[0m
Packer v1.0.2

Your version of Packer is out of date! The latest version
is 1.1.2. You can update by downloading from www.packer.io
[34m[1mpostgresql client version[0m
psql (PostgreSQL) 9.6.6
[34m[1mragel version[0m
Ragel State Machine Compiler version 6.8 Feb 2013
Copyright (c) 2001-2009 by Adrian Thurston
[34m[1msubversion version[0m
svn, version 1.8.8 (r1568071)
   compiled Aug 10 2017, 17:20:39 on x86_64-pc-linux-gnu

Copyright (C) 2013 The Apache Software Foundation.
This software consists of contributions made by many people;
see the NOTICE file for more information.
Subversion is open source software, see http://subversion.apache.org/

The following repository access (RA) modules are available:

* ra_svn : Module for accessing a repository using the svn network protocol.
  - with Cyrus SASL authentication
  - handles 'svn' scheme
* ra_local : Module for accessing a repository on local disk.
  - handles 'file' scheme
* ra_serf : Module for accessing a repository via WebDAV protocol using serf.
  - using serf 1.3.3
  - handles 'http' scheme
  - handles 'https' scheme

[34m[1msudo version[0m
Sudo version 1.8.9p5
Configure options: --prefix=/usr -v --with-all-insults --with-pam --with-fqdn --with-logging=syslog --with-logfac=authpriv --with-env-editor --with-editor=/usr/bin/editor --with-timeout=15 --with-password-timeout=0 --with-passprompt=[sudo] password for %p:  --without-lecture --with-tty-tickets --disable-root-mailer --enable-admin-flag --with-sendmail=/usr/sbin/sendmail --with-timedir=/var/lib/sudo --mandir=/usr/share/man --libexecdir=/usr/lib/sudo --with-sssd --with-sssd-lib=/usr/lib/x86_64-linux-gnu --with-selinux
Sudoers policy plugin version 1.8.9p5
Sudoers file grammar version 43

Sudoers path: /etc/sudoers
Authentication methods: 'pam'
Syslog facility if syslog is being used for logging: authpriv
Syslog priority to use when user authenticates successfully: notice
Syslog priority to use when user authenticates unsuccessfully: alert
Send mail if the user is not in sudoers
Use a separate timestamp for each user/tty combo
Lecture user the first time they run sudo
Root may run sudo
Allow some information gathering to give useful error messages
Require fully-qualified hostnames in the sudoers file
Visudo will honor the EDITOR environment variable
Set the LOGNAME and USER environment variables
Length at which to wrap log file lines (0 for no wrap): 80
Authentication timestamp timeout: 15.0 minutes
Password prompt timeout: 0.0 minutes
Number of tries to enter a password: 3
Umask to use or 0777 to use user's: 022
Path to mail program: /usr/sbin/sendmail
Flags for mail program: -t
Address to send mail to: root
Subject line for mail messages: *** SECURITY information for %h ***
Incorrect password message: Sorry, try again.
Path to authentication timestamp dir: /var/lib/sudo
Default password prompt: [sudo] password for %p: 
Default user to run commands as: root
Value to override user's $PATH with: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
Path to the editor for use by visudo: /usr/bin/editor
When to require a password for 'list' pseudocommand: any
When to require a password for 'verify' pseudocommand: all
File descriptors >= 3 will be closed before executing a command
Environment variables to check for sanity:
	TZ
	TERM
	LINGUAS
	LC_*
	LANGUAGE
	LANG
	COLORTERM
Environment variables to remove:
	RUBYOPT
	RUBYLIB
	PYTHONUSERBASE
	PYTHONINSPECT
	PYTHONPATH
	PYTHONHOME
	TMPPREFIX
	ZDOTDIR
	READNULLCMD
	NULLCMD
	FPATH
	PERL5DB
	PERL5OPT
	PERL5LIB
	PERLLIB
	PERLIO_DEBUG 
	JAVA_TOOL_OPTIONS
	SHELLOPTS
	GLOBIGNORE
	PS4
	BASH_ENV
	ENV
	TERMCAP
	TERMPATH
	TERMINFO_DIRS
	TERMINFO
	_RLD*
	LD_*
	PATH_LOCALE
	NLSPATH
	HOSTALIASES
	RES_OPTIONS
	LOCALDOMAIN
	CDPATH
	IFS
Environment variables to preserve:
	JAVA_HOME
	TRAVIS
	CI
	DEBIAN_FRONTEND
	XAUTHORIZATION
	XAUTHORITY
	PS2
	PS1
	PATH
	LS_COLORS
	KRB5CCNAME
	HOSTNAME
	HOME
	DISPLAY
	COLORS
Locale to use while parsing sudoers: C
Directory in which to store input/output logs: /var/log/sudo-io
File in which to store the input/output log: %{seq}
Add an entry to the utmp/utmpx file when allocating a pty
PAM service name to use
PAM service name to use for login shells
Create a new PAM session for the command to run in
Maximum I/O log sequence number: 0

Local IP address and netmask pairs:
	172.17.0.2/255.255.0.0

Sudoers I/O plugin version 1.8.9p5
[34m[1mgzip version[0m
gzip 1.6
Copyright (C) 2007, 2010, 2011 Free Software Foundation, Inc.
Copyright (C) 1993 Jean-loup Gailly.
This is free software.  You may redistribute copies of it under the terms of
the GNU General Public License <http://www.gnu.org/licenses/gpl.html>.
There is NO WARRANTY, to the extent permitted by law.

Written by Jean-loup Gailly.
[34m[1mzip version[0m
Copyright (c) 1990-2008 Info-ZIP - Type 'zip "-L"' for software license.
This is Zip 3.0 (July 5th 2008), by Info-ZIP.
Currently maintained by E. Gordon.  Please send bug reports to
the authors using the web page at www.info-zip.org; see README for details.

Latest sources and executables are at ftp://ftp.info-zip.org/pub/infozip,
as of above date; see http://www.info-zip.org/ for other sites.

Compiled with gcc 4.8.2 for Unix (Linux ELF) on Oct 21 2013.

Zip special compilation options:
	USE_EF_UT_TIME       (store Universal Time)
	BZIP2_SUPPORT        (bzip2 library version 1.0.6, 6-Sept-2010)
	    bzip2 code and library copyright (c) Julian R Seward
	    (See the bzip2 license for terms of use)
	SYMLINK_SUPPORT      (symbolic links supported)
	LARGE_FILE_SUPPORT   (can read and write large files on file system)
	ZIP64_SUPPORT        (use Zip64 to store large files in archives)
	UNICODE_SUPPORT      (store and read UTF-8 Unicode paths)
	STORE_UNIX_UIDs_GIDs (store UID/GID sizes/values using new extra field)
	UIDGID_NOT_16BIT     (old Unix 16-bit UID/GID extra field not used)
	[encryption, version 2.91 of 05 Jan 2007] (modified for Zip 3)

Encryption notice:
	The encryption code of this program is not copyrighted and is
	put in the public domain.  It was originally written in Europe
	and, to the best of our knowledge, can be freely distributed
	in both source and object forms from any country, including
	the USA under License Exception TSU of the U.S. Export
	Administration Regulations (section 740.13(e)) of 6 June 2002.

Zip environment options:
             ZIP:  [none]
          ZIPOPT:  [none]
[34m[1mvim version[0m
VIM - Vi IMproved 7.4 (2013 Aug 10, compiled Nov 24 2016 16:43:18)
Included patches: 1-52
Extra patches: 8.0.0056
Modified by pkg-vim-maintainers@lists.alioth.debian.org
Compiled by buildd@
Huge version without GUI.  Features included (+) or not (-):
+acl             +farsi           +mouse_netterm   +syntax
+arabic          +file_in_path    +mouse_sgr       +tag_binary
+autocmd         +find_in_path    -mouse_sysmouse  +tag_old_static
-balloon_eval    +float           +mouse_urxvt     -tag_any_white
-browse          +folding         +mouse_xterm     -tcl
++builtin_terms  -footer          +multi_byte      +terminfo
+byte_offset     +fork()          +multi_lang      +termresponse
+cindent         +gettext         -mzscheme        +textobjects
-clientserver    -hangul_input    +netbeans_intg   +title
-clipboard       +iconv           +path_extra      -toolbar
+cmdline_compl   +insert_expand   -perl            +user_commands
+cmdline_hist    +jumplist        +persistent_undo +vertsplit
+cmdline_info    +keymap          +postscript      +virtualedit
+comments        +langmap         +printer         +visual
+conceal         +libcall         +profile         +visualextra
+cryptv          +linebreak       +python          +viminfo
+cscope          +lispindent      -python3         +vreplace
+cursorbind      +listcmds        +quickfix        +wildignore
+cursorshape     +localmap        +reltime         +wildmenu
+dialog_con      -lua             +rightleft       +windows
+diff            +menu            -ruby            +writebackup
+digraphs        +mksession       +scrollbind      -X11
-dnd             +modify_fname    +signs           -xfontset
-ebcdic          +mouse           +smartindent     -xim
+emacs_tags      -mouseshape      -sniff           -xsmp
+eval            +mouse_dec       +startuptime     -xterm_clipboard
+ex_extra        +mouse_gpm       +statusline      -xterm_save
+extra_search    -mouse_jsbterm   -sun_workshop    -xpm
   system vimrc file: "$VIM/vimrc"
     user vimrc file: "$HOME/.vimrc"
 2nd user vimrc file: "~/.vim/vimrc"
      user exrc file: "$HOME/.exrc"
  fall-back for $VIM: "/usr/share/vim"
Compilation: gcc -c -I. -Iproto -DHAVE_CONFIG_H     -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1      
Linking: gcc   -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,--as-needed -o vim        -lm -ltinfo -lnsl  -lselinux  -lacl -lattr -lgpm -ldl    -L/usr/lib/python2.7/config-x86_64-linux-gnu -lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions      
[34m[1miptables version[0m
iptables v1.4.21
[34m[1mcurl version[0m
curl 7.35.0 (x86_64-pc-linux-gnu) libcurl/7.35.0 OpenSSL/1.0.1f zlib/1.2.8 libidn/1.28 librtmp/2.3
[34m[1mwget version[0m
GNU Wget 1.15 built on linux-gnu.
[34m[1mrsync version[0m
rsync  version 3.1.0  protocol version 31
[34m[1mgimme version[0m
v1.2.0
[34m[1mnvm version[0m
0.33.6
[34m[1mperlbrew version[0m
/home/travis/perl5/perlbrew/bin/perlbrew  - App::perlbrew/0.80
[34m[1mphpenv version[0m
rbenv 1.1.1-25-g6aa70b6
[34m[1mrvm version[0m
rvm 1.29.3 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io]
[34m[1mdefault ruby version[0m
ruby 2.4.1p111 (2017-03-22 revision 58053) [x86_64-linux]
[34m[1mCouchDB version[0m
couchdb 1.6.1
[34m[1mElasticSearch version[0m
5.5.0
[34m[1mInstalled Firefox version[0m
firefox 56.0.2
[34m[1mMongoDB version[0m
MongoDB 3.4.10
[34m[1mPhantomJS version[0m
2.1.1
[34m[1mPre-installed PostgreSQL versions[0m
9.2.24
9.3.20
9.4.15
9.5.10
9.6.6
[34m[1mRabbitMQ Version[0m
3.6.14
[34m[1mRedis version[0m
redis-server 4.0.6
[34m[1mriak version[0m
2.2.3
[34m[1mPre-installed Go versions[0m
1.7.4
[34m[1mant version[0m
Apache Ant(TM) version 1.9.3 compiled on April 8 2014
[34m[1mmvn version[0m
Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z)
Maven home: /usr/local/maven-3.5.2
Java version: 1.8.0_151, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-8-oracle/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.4.0-101-generic", arch: "amd64", family: "unix"
[34m[1mgradle version[0m

------------------------------------------------------------
Gradle 4.0.1
------------------------------------------------------------

Build time:   2017-07-07 14:02:41 UTC
Revision:     38e5dc0f772daecca1d2681885d3d85414eb6826

Groovy:       2.4.11
Ant:          Apache Ant(TM) version 1.9.6 compiled on June 29 2015
JVM:          1.8.0_151 (Oracle Corporation 25.151-b12)
OS:           Linux 4.4.0-101-generic amd64

[34m[1mlein version[0m
Leiningen 2.8.1 on Java 1.8.0_151 Java HotSpot(TM) 64-Bit Server VM
[34m[1mPre-installed Node.js versions[0m
v4.8.6
v6.12.0
v6.12.1
v8.9
v8.9.1
[34m[1mphpenv versions[0m
  system
  5.6
* 5.6.32 (set by /home/travis/.phpenv/version)
  7.0
  7.0.25
  7.1
  7.1.11
  hhvm
  hhvm-stable
[34m[1mcomposer --version[0m
Composer version 1.5.2 2017-09-11 16:59:25
[34m[1mPre-installed Ruby versions[0m
ruby-2.2.7
ruby-2.3.4
ruby-2.4.1
travis_fold:end:system_info[0K
grep: /etc/apt/sources.list.d/*: No such file or directory
sed: cannot rename /etc/hosts: Device or resource busy
sed: cannot rename /etc/hosts: Device or resource busy
$ jdk_switcher use oraclejdk8
Switching to Oracle JDK8 (java-8-oracle), JAVA_HOME will be set to /usr/lib/jvm/java-8-oracle
$ cd passed/brianfrankcooper/YCSB
travis_fold:start:services[0Ktravis_time:start:17cd9c9d[0K$ sudo service mongod start
initctl: Unable to connect to Upstart: Failed to connect to socket /com/ubuntu/upstart: Connection refused
mongod: unrecognized service

travis_time:end:17cd9c9d:start=1606442227648349470,finish=1606442227675299382,duration=26949912[0Ktravis_fold:end:services[0K$ java -Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
java version "1.8.0_151"
Java(TM) SE Runtime Environment (build 1.8.0_151-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode)
$ javac -J-Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
javac 1.8.0_151
travis_fold:start:install[0Ktravis_time:start:06f32585[0K$ mvn install -Dhttps.protocols=TLSv1.2 -q -DskipTests=true
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[INFO] Skipping plugin execution
[INFO] Skipping plugin execution

travis_time:end:06f32585:start=1606442231653166670,finish=1606442436529479433,duration=204876312763[0Ktravis_fold:end:install[0Ktravis_time:start:16f43aae[0K$ mvn test -Dhttps.protocols=TLSv1.2 -q
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running TestSuite
Configuring TestNG with: org.apache.maven.surefire.testng.conf.TestNGMapConfigurator@255316f2
Tests run: 40, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.179 sec

Results :

Tests run: 40, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.accumulo.AccumuloTest
Using 20 threads to write data
Using 20 threads to write data
Using 20 threads to write data
Using 20 threads to write data
Using 20 threads to write data
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 57.524 sec

Results :

Tests run: 5, Failures: 0, Errors: 0, Skipped: 0

2020/11/27 02:01:49 WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Formatting using clusterid: testClusterID
2020/11/27 02:01:50 WARN  org.apache.hadoop.metrics2.impl.MetricsConfig  - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020/11/27 02:01:50 WARN  org.apache.hadoop.security.authentication.server.AuthenticationFilter  - 'signature.secret' configuration not set, using a random value as secret
2020/11/27 02:01:52 WARN  org.apache.hadoop.hbase.ZNodeClearer  - Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2020/11/27 02:01:53 WARN  org.apache.hadoop.hbase.HTableDescriptor  - Use addCoprocessor* methods to add a coprocessor instead
2020/11/27 02:01:53 WARN  org.apache.hadoop.hbase.ZNodeClearer  - Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2020/11/27 02:02:04 WARN  org.apache.zookeeper.server.persistence.FileTxnLog  - fsync-ing the write ahead log in SyncThread:0 took 1252ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2020/11/27 02:02:14 WARN  org.apache.hadoop.hdfs.server.datanode.DirectoryScanner  - DirectoryScanner: shutdown has been called
2020/11/27 02:02:14 WARN  org.apache.hadoop.hdfs.server.datanode.DataNode  - BPOfferService for Block pool BP-984669344-172.17.0.8-1606442510038 (Datanode Uuid 803c2f78-149c-46fe-b3d6-d6c6ed50a7aa) service to localhost/127.0.0.1:33773 interrupted
2020/11/27 02:02:14 WARN  org.apache.hadoop.hdfs.server.datanode.DataNode  - Ending block pool service for: Block pool BP-984669344-172.17.0.8-1606442510038 (Datanode Uuid 803c2f78-149c-46fe-b3d6-d6c6ed50a7aa) service to localhost/127.0.0.1:33773
2020/11/27 02:02:14 WARN  org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager  - Monitor interrupted: java.lang.InterruptedException: sleep interrupted
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.yahoo.ycsb.db.CassandraCQLClientTest
[main] INFO org.apache.cassandra.config.YamlConfigurationLoader - Configuration location: file:/home/travis/build/passed/brianfrankcooper/YCSB/cassandra/target/embeddedCassandra/cu-cassandra.yaml
[main] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[main] INFO org.apache.cassandra.config.DatabaseDescriptor - DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
[main] INFO org.apache.cassandra.config.DatabaseDescriptor - Global memtable on-heap threshold is enabled at 455MB
[main] INFO org.apache.cassandra.config.DatabaseDescriptor - Global memtable off-heap threshold is enabled at 455MB
[main] WARN org.apache.cassandra.config.DatabaseDescriptor - Please rename encryption_options as server_encryption_options in the yaml
[main] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[main] INFO org.apache.cassandra.db.commitlog.CommitLog - No commitlog files found; skipping replay
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Hostname: fe80c75c39e7
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - JVM vendor/version: Java HotSpot(TM) 64-Bit Server VM/1.8.0_151
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Heap size: 514850816/1908932608
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Code Cache Non-heap memory: init = 2555904(2496K) used = 6460864(6309K) committed = 6553600(6400K) max = 251658240(245760K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Metaspace Non-heap memory: init = 0(0K) used = 15423728(15062K) committed = 15990784(15616K) max = -1(-1K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Compressed Class Space Non-heap memory: init = 0(0K) used = 1883128(1838K) committed = 2097152(2048K) max = 1073741824(1048576K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - PS Eden Space Heap memory: init = 134742016(131584K) used = 97016912(94743K) committed = 134742016(131584K) max = 671612928(655872K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - PS Survivor Space Heap memory: init = 22020096(21504K) used = 0(0K) committed = 22020096(21504K) max = 22020096(21504K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - PS Old Gen Heap memory: init = 358088704(349696K) used = 0(0K) committed = 358088704(349696K) max = 1431830528(1398272K)
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - Classpath: /home/travis/build/passed/brianfrankcooper/YCSB/cassandra/target/test-classes:/home/travis/build/passed/brianfrankcooper/YCSB/cassandra/target/classes:/home/travis/.m2/repository/com/datastax/cassandra/cassandra-driver-core/3.0.0/cassandra-driver-core-3.0.0.jar:/home/travis/.m2/repository/io/netty/netty-handler/4.0.33.Final/netty-handler-4.0.33.Final.jar:/home/travis/.m2/repository/io/netty/netty-buffer/4.0.33.Final/netty-buffer-4.0.33.Final.jar:/home/travis/.m2/repository/io/netty/netty-common/4.0.33.Final/netty-common-4.0.33.Final.jar:/home/travis/.m2/repository/io/netty/netty-transport/4.0.33.Final/netty-transport-4.0.33.Final.jar:/home/travis/.m2/repository/io/netty/netty-codec/4.0.33.Final/netty-codec-4.0.33.Final.jar:/home/travis/.m2/repository/com/google/guava/guava/16.0.1/guava-16.0.1.jar:/home/travis/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.2/metrics-core-3.1.2.jar:/home/travis/build/passed/brianfrankcooper/YCSB/core/target/classes:/home/travis/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar:/home/travis/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.4/jackson-mapper-asl-1.9.4.jar:/home/travis/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.4/jackson-core-asl-1.9.4.jar:/home/travis/.m2/repository/org/hdrhistogram/HdrHistogram/2.1.4/HdrHistogram-2.1.4.jar:/home/travis/.m2/repository/org/cassandraunit/cassandra-unit/3.0.0.1/cassandra-unit-3.0.0.1-shaded.jar:/home/travis/.m2/repository/org/apache/cassandra/cassandra-all/3.4/cassandra-all-3.4.jar:/home/travis/.m2/repository/org/xerial/snappy/snappy-java/1.1.1.7/snappy-java-1.1.1.7.jar:/home/travis/.m2/repository/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar:/home/travis/.m2/repository/com/ning/compress-lzf/0.8.4/compress-lzf-0.8.4.jar:/home/travis/.m2/repository/commons-cli/commons-cli/1.1/commons-cli-1.1.jar:/home/travis/.m2/repository/commons-codec/commons-codec/1.2/commons-codec-1.2.jar:/home/travis/.m2/repository/org/apache/commons/commons-math3/3.2/commons-math3-3.2.jar:/home/travis/.m2/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4/concurrentlinkedhashmap-lru-1.4.jar:/home/travis/.m2/repository/org/antlr/antlr/3.5.2/antlr-3.5.2.jar:/home/travis/.m2/repository/org/antlr/ST4/4.0.8/ST4-4.0.8.jar:/home/travis/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar:/home/travis/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.7/jcl-over-slf4j-1.7.7.jar:/home/travis/.m2/repository/com/googlecode/json-simple/json-simple/1.1/json-simple-1.1.jar:/home/travis/.m2/repository/com/boundary/high-scale-lib/1.0.6/high-scale-lib-1.0.6.jar:/home/travis/.m2/repository/org/yaml/snakeyaml/1.11/snakeyaml-1.11.jar:/home/travis/.m2/repository/org/mindrot/jbcrypt/0.3m/jbcrypt-0.3m.jar:/home/travis/.m2/repository/com/addthis/metrics/reporter-config3/3.0.0/reporter-config3-3.0.0.jar:/home/travis/.m2/repository/com/addthis/metrics/reporter-config-base/3.0.0/reporter-config-base-3.0.0.jar:/home/travis/.m2/repository/com/thinkaurelius/thrift/thrift-server/0.3.7/thrift-server-0.3.7.jar:/home/travis/.m2/repository/com/lmax/disruptor/3.0.1/disruptor-3.0.1.jar:/home/travis/.m2/repository/com/clearspring/analytics/stream/2.5.2/stream-2.5.2.jar:/home/travis/.m2/repository/it/unimi/dsi/fastutil/6.5.7/fastutil-6.5.7.jar:/home/travis/.m2/repository/org/apache/thrift/libthrift/0.9.2/libthrift-0.9.2.jar:/home/travis/.m2/repository/org/apache/cassandra/cassandra-thrift/3.4/cassandra-thrift-3.4.jar:/home/travis/.m2/repository/com/carrotsearch/hppc/0.5.4/hppc-0.5.4.jar:/home/travis/.m2/repository/de/jflex/jflex/1.6.0/jflex-1.6.0.jar:/home/travis/.m2/repository/org/apache/ant/ant/1.7.0/ant-1.7.0.jar:/home/travis/.m2/repository/org/apache/ant/ant-launcher/1.7.0/ant-launcher-1.7.0.jar:/home/travis/.m2/repository/net/mintern/primitive/1.0/primitive-1.0.jar:/home/travis/.m2/repository/com/github/rholder/snowball-stemmer/1.3.0.581.1/snowball-stemmer-1.3.0.581.1.jar:/home/travis/.m2/repository/com/googlecode/concurrent-trees/concurrent-trees/2.4.0/concurrent-trees-2.4.0.jar:/home/travis/.m2/repository/net/java/dev/jna/jna/4.0.0/jna-4.0.0.jar:/home/travis/.m2/repository/com/github/jbellis/jamm/0.3.0/jamm-0.3.0.jar:/home/travis/.m2/repository/joda-time/joda-time/2.4/joda-time-2.4.jar:/home/travis/.m2/repository/org/fusesource/sigar/1.6.4/sigar-1.6.4.jar:/home/travis/.m2/repository/org/eclipse/jdt/core/compiler/ecj/4.4.2/ecj-4.4.2.jar:/home/travis/.m2/repository/org/caffinitas/ohc/ohc-core/0.4.2/ohc-core-0.4.2.jar:/home/travis/.m2/repository/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar:/home/travis/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/travis/.m2/repository/org/hamcrest/hamcrest-library/1.3/hamcrest-library-1.3.jar:/home/travis/.m2/repository/org/slf4j/slf4j-api/1.6.4/slf4j-api-1.6.4.jar:/home/travis/.m2/repository/org/slf4j/slf4j-simple/1.7.21/slf4j-simple-1.7.21.jar:/home/travis/.m2/repository/junit/junit/4.12/junit-4.12.jar:
[pool-1-thread-1] INFO org.apache.cassandra.service.CassandraDaemon - JVM Arguments: [-Djava.library.path=/home/travis/build/passed/brianfrankcooper/YCSB/cassandra/target/cassandra-dependency/hyperic-sigar-1.6.4/sigar-bin/lib, -Xmx2048m, -Xms512m]
[pool-1-thread-1] WARN org.apache.cassandra.utils.CLibrary - Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.
[pool-1-thread-1] WARN org.apache.cassandra.service.StartupChecks - jemalloc shared library could not be preloaded to speed up memory allocations
[pool-1-thread-1] WARN org.apache.cassandra.service.StartupChecks - JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.
[pool-1-thread-1] ERROR org.apache.cassandra.service.StartupChecks - cassandra.jmx.local.port missing from cassandra-env.sh, unable to start local JMX service.
[pool-1-thread-1] INFO org.apache.cassandra.utils.SigarLibrary - Initializing SIGAR library
[pool-1-thread-1] WARN org.apache.cassandra.utils.SigarLibrary - Cassandra server running in degraded mode. Is swap disabled? : false,  Address space adequate? : true,  nofile limit adequate? : true, nproc limit adequate? : true 
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.IndexInfo
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.batches
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.paxos
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.local
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.peers
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.peer_events
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.range_xfers
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.compaction_history
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.sstable_activity
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.size_estimates
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.available_ranges
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.views_builds_in_progress
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.built_views
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.hints
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.batchlog
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_keyspaces
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_columnfamilies
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_columns
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_triggers
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_usertypes
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_functions
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system.schema_aggregates
[MemtableFlushWriter:1] INFO org.apache.cassandra.service.CacheService - Initializing key cache with capacity of 24 MBs.
[MemtableFlushWriter:1] INFO org.apache.cassandra.service.CacheService - Initializing row cache with capacity of 0 MBs
[MemtableFlushWriter:1] INFO org.apache.cassandra.service.CacheService - Initializing counter cache with capacity of 12 MBs
[MemtableFlushWriter:1] INFO org.apache.cassandra.service.CacheService - Scheduling counter cache save to every 7200 seconds (going to save all keys).
[CompactionExecutor:2] INFO org.apache.cassandra.utils.memory.BufferPool - Global buffer pool is enabled, when pool is exahusted (max is 512 mb) it will allocate on heap
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Populating token metadata from system tables
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Token metadata: 
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.keyspaces
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.tables
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.columns
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.triggers
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.dropped_columns
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.views
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.types
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.functions
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.aggregates
[pool-1-thread-1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_schema.indexes
[pool-1-thread-1] INFO org.apache.cassandra.cache.AutoSavingCache - Completed loading (3 ms; 9 keys) KeyCache cache
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Populating token metadata from system tables
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Token metadata: 
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Cassandra version: 3.4
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Thrift API version: 20.1.0
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - CQL supported versions: 3.4.0 (default: 3.4.0)
[pool-1-thread-1] INFO org.apache.cassandra.io.sstable.IndexSummaryManager - Initializing index summary manager with a memory pool size of 24 MB and a resize interval of 60 minutes
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Loading persisted ring state
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] WARN org.apache.cassandra.db.SystemKeyspace - No host ID found, created ca6b3d9b-affc-4abe-82d5-a7c1b7bd1074 (Note: This should happen exactly once per node).
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Starting up server gossip
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] INFO org.apache.cassandra.net.MessagingService - Starting Messaging Service on /127.0.0.1:7010 (lo)
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - This node will not auto bootstrap because it is configured to be a seed node.
[pool-1-thread-1] INFO org.apache.cassandra.config.YamlConfigurationLoader - Node configuration:[authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_snapshot=false; cas_contention_timeout_in_ms=1000; cluster_name=Test Cluster; column_index_size_in_kb=64; commitlog_directory=target/embeddedCassandra/commitlog; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_period_in_ms=10000; compaction_throughput_mb_per_sec=16; concurrent_reads=32; concurrent_writes=32; cross_node_timeout=false; data_file_directories=[target/embeddedCassandra/data]; disk_failure_policy=stop; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; encryption_options={internode_encryption=none, keystore=conf/.keystore, keystore_password=cassandra, truststore=conf/.truststore, truststore_password=cassandra}; endpoint_snitch=SimpleSnitch; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_directory=target/embeddedCassandra/hints; incremental_backups=false; index_interval=128; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=127.0.0.1; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; native_transport_port=9142; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_validity_in_ms=2000; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_timeout_in_ms=10000; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=localhost; rpc_keepalive=true; rpc_port=9171; rpc_server_type=sync; saved_caches_directory=target/embeddedCassandra/saved_caches; seed_provider=[{class_name=org.apache.cassandra.locator.SimpleSeedProvider, parameters=[{seeds=127.0.0.1}]}]; snapshot_before_compaction=false; ssl_storage_port=7011; start_native_transport=true; start_rpc=true; storage_port=7010; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; write_request_timeout_in_ms=2000]
[pool-1-thread-1] WARN org.apache.cassandra.service.StorageService - Generated random token [8423710549932250565]. Random tokens will result in an unbalanced ring; see http://wiki.apache.org/cassandra/Operations
[pool-1-thread-1] INFO org.apache.cassandra.service.MigrationManager - Create new Keyspace: KeyspaceMetadata{name=system_traces, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}, tables=[org.apache.cassandra.config.CFMetaData@560ace75[cfId=c5e99f16-8677-3914-b17e-960613512345,ksName=system_traces,cfName=sessions,flags=[COMPOUND],params=TableParams{comment=tracing sessions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@f3cd4536, extensions={}},comparator=comparator(),partitionColumns=[[] | [client command coordinator duration request started_at parameters]],partitionKeyColumns=[ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, position=0}],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[ColumnDefinition{name=client, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, position=-1}, ColumnDefinition{name=command, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=coordinator, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, position=-1}, ColumnDefinition{name=request, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=started_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=duration, type=org.apache.cassandra.db.marshal.Int32Type, kind=REGULAR, position=-1}, ColumnDefinition{name=parameters, type=org.apache.cassandra.db.marshal.MapType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@36ba893e[cfId=8826e8e9-e16a-3728-8753-3bc1fc713c25,ksName=system_traces,cfName=events,flags=[COMPOUND],params=TableParams{comment=tracing events, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@f3cd4536, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [activity source source_elapsed thread]],partitionKeyColumns=[ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, position=0}],clusteringColumns=[ColumnDefinition{name=event_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[ColumnDefinition{name=activity, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=session_id, type=org.apache.cassandra.db.marshal.UUIDType, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=thread, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=event_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING, position=0}, ColumnDefinition{name=source, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, position=-1}, ColumnDefinition{name=source_elapsed, type=org.apache.cassandra.db.marshal.Int32Type, kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_traces.events
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_traces.sessions
[pool-1-thread-1] INFO org.apache.cassandra.service.MigrationManager - Create new Keyspace: KeyspaceMetadata{name=system_distributed, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}, tables=[org.apache.cassandra.config.CFMetaData@20f06111[cfId=759fffad-624b-3181-80ee-fa9a52d1f627,ksName=system_distributed,cfName=repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@f3cd4536, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [coordinator exception_message exception_stacktrace finished_at parent_id range_begin range_end started_at status participants]],partitionKeyColumns=[ColumnDefinition{name=keyspace_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=columnfamily_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=1}],clusteringColumns=[ColumnDefinition{name=id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[ColumnDefinition{name=status, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=CLUSTERING, position=0}, ColumnDefinition{name=coordinator, type=org.apache.cassandra.db.marshal.InetAddressType, kind=REGULAR, position=-1}, ColumnDefinition{name=finished_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=participants, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.InetAddressType), kind=REGULAR, position=-1}, ColumnDefinition{name=exception_stacktrace, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=parent_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=REGULAR, position=-1}, ColumnDefinition{name=range_end, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=range_begin, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=exception_message, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=keyspace_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=started_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=columnfamily_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=1}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@5be53365[cfId=deabd734-b99d-3b9c-92e5-fd92eb5abf14,ksName=system_distributed,cfName=parent_repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@f3cd4536, extensions={}},comparator=comparator(),partitionColumns=[[] | [exception_message exception_stacktrace finished_at keyspace_name started_at columnfamily_names requested_ranges successful_ranges]],partitionKeyColumns=[ColumnDefinition{name=parent_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=PARTITION_KEY, position=0}],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[ColumnDefinition{name=requested_ranges, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}, ColumnDefinition{name=exception_message, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=keyspace_name, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=successful_ranges, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}, ColumnDefinition{name=started_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=finished_at, type=org.apache.cassandra.db.marshal.TimestampType, kind=REGULAR, position=-1}, ColumnDefinition{name=exception_stacktrace, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=parent_id, type=org.apache.cassandra.db.marshal.TimeUUIDType, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=columnfamily_names, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_distributed.parent_repair_history
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_distributed.repair_history
[pool-1-thread-1] INFO org.apache.cassandra.service.StorageService - Node /127.0.0.1 state jump to NORMAL
[pool-1-thread-1] INFO org.apache.cassandra.service.MigrationManager - Create new Keyspace: KeyspaceMetadata{name=system_auth, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[org.apache.cassandra.config.CFMetaData@31ed47cb[cfId=5bc52802-de25-35ed-aeab-188eecebb090,ksName=system_auth,cfName=roles,flags=[COMPOUND],params=TableParams{comment=role definitions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@f3cd4536, extensions={}},comparator=comparator(),partitionColumns=[[] | [can_login is_superuser salted_hash member_of]],partitionKeyColumns=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=salted_hash, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=member_of, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}, ColumnDefinition{name=can_login, type=org.apache.cassandra.db.marshal.BooleanType, kind=REGULAR, position=-1}, ColumnDefinition{name=is_superuser, type=org.apache.cassandra.db.marshal.BooleanType, kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@31d53356[cfId=0ecdaa87-f8fb-3e60-88d1-74fb36fe5c0d,ksName=system_auth,cfName=role_members,flags=[COMPOUND],params=TableParams{comment=role memberships lookup table, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@f3cd4536, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[ColumnDefinition{name=member, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=member, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@7b77e7ab[cfId=3afbe79f-2194-31a7-add7-f5ab90d8ec9c,ksName=system_auth,cfName=role_permissions,flags=[COMPOUND],params=TableParams{comment=permissions granted to db roles, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@f3cd4536, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [permissions]],partitionKeyColumns=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[ColumnDefinition{name=resource, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=resource, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}, ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=permissions, type=org.apache.cassandra.db.marshal.SetType(org.apache.cassandra.db.marshal.UTF8Type), kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@48d4a8b8[cfId=5f2fbdad-91f1-3946-bd25-d5da3a5c35ec,ksName=system_auth,cfName=resource_role_permissons_index,flags=[COMPOUND],params=TableParams{comment=index of db roles with permissions granted on a resource, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@f3cd4536, extensions={}},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[ColumnDefinition{name=resource, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=resource, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=role, type=org.apache.cassandra.db.marshal.UTF8Type, kind=CLUSTERING, position=0}],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_auth.resource_role_permissons_index
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_auth.role_members
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_auth.role_permissions
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing system_auth.roles
[pool-1-thread-1] INFO org.apache.cassandra.service.NativeTransportService - Netty using Java NIO event loop
[pool-1-thread-1] INFO org.apache.cassandra.transport.Server - Using Netty Version: [netty-buffer=netty-buffer-4.0.33.Final.69b5aef, netty-codec=netty-codec-4.0.33.Final.69b5aef, netty-common=netty-common-4.0.33.Final.69b5aef, netty-handler=netty-handler-4.0.27.Final.054e7c5, netty-transport=netty-transport-4.0.33.Final.69b5aef]
[pool-1-thread-1] INFO org.apache.cassandra.transport.Server - Starting listening for CQL clients on localhost/127.0.0.1:9142 (unencrypted)...
[pool-1-thread-1] INFO org.cassandraunit.shaded.org.apache.cassandra.thrift.ThriftServer - Binding thrift service to localhost/127.0.0.1:9171
[Thread-1] INFO org.cassandraunit.shaded.org.apache.cassandra.thrift.ThriftServer - Listening for thrift clients...
[main] INFO com.datastax.driver.core.NettyUtil - Did not find Netty's native epoll transport in the classpath, defaulting to NIO.
[SharedPool-Worker-4] INFO org.apache.cassandra.db.monitoring.ApproximateTime - Scheduling approximate time-check task with a precision of 10 milliseconds
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
[SharedPool-Worker-1] INFO org.apache.cassandra.service.MigrationManager - Create new Keyspace: KeyspaceMetadata{name=ycsb, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[], views=[], functions=[], types=[]}
[SharedPool-Worker-7] INFO org.apache.cassandra.service.MigrationManager - Create new table: org.apache.cassandra.config.CFMetaData@d7a1b49[cfId=974bb780-3054-11eb-b49f-1528853c6b3e,ksName=ycsb,cfName=usertable,flags=[COMPOUND],params=TableParams{comment=, read_repair_chance=0.0, dclocal_read_repair_chance=0.1, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=864000, default_time_to_live=0, memtable_flush_period_in_ms=0, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={'keys' : 'ALL', 'rows_per_partition' : 'NONE'}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@f3cd4536, extensions={}},comparator=comparator(),partitionColumns=[[] | [field0 field1 field2 field3 field4 field5 field6 field7 field8 field9]],partitionKeyColumns=[ColumnDefinition{name=y_id, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[ColumnDefinition{name=field7, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field4, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field2, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field0, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field3, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field6, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field8, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field5, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=field9, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}, ColumnDefinition{name=y_id, type=org.apache.cassandra.db.marshal.UTF8Type, kind=PARTITION_KEY, position=0}, ColumnDefinition{name=field1, type=org.apache.cassandra.db.marshal.UTF8Type, kind=REGULAR, position=-1}],droppedColumns={},triggers=[],indexes=[]]
[MigrationStage:1] INFO org.apache.cassandra.db.ColumnFamilyStore - Initializing ycsb.usertable
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
Connected to cluster: Test Cluster
Datacenter: datacenter1; Host: localhost/127.0.0.1; Rack: rack1
[SharedPool-Worker-1] WARN org.apache.cassandra.utils.FBUtilities - Trigger directory doesn't exist, please create it and try again.
[HANDSHAKE-/127.0.0.1] INFO org.apache.cassandra.net.OutboundTcpConnection - Handshaking version with /127.0.0.1
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
Connected to cluster: Test Cluster
Datacenter: datacenter1; Host: localhost/127.0.0.1; Rack: rack1
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
Connected to cluster: Test Cluster
Datacenter: datacenter1; Host: localhost/127.0.0.1; Rack: rack1
[OptionalTasks:1] INFO org.apache.cassandra.auth.CassandraRoleManager - Created default superuser role 'cassandra'
[main] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)
[main] INFO com.datastax.driver.core.Cluster - New Cassandra host localhost/127.0.0.1:9142 added
Connected to cluster: Test Cluster
Datacenter: datacenter1; Host: localhost/127.0.0.1; Rack: rack1
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 20.949 sec

Results :

Tests run: 4, Failures: 0, Errors: 0, Skipped: 0

[StorageServiceShutdownHook] INFO org.cassandraunit.shaded.org.apache.cassandra.thrift.ThriftServer - Stop listening to thrift clients
[StorageServiceShutdownHook] INFO org.apache.cassandra.transport.Server - Stop listening for CQL clients
[StorageServiceShutdownHook] INFO org.apache.cassandra.gms.Gossiper - Announcing shutdown
[StorageServiceShutdownHook] INFO org.apache.cassandra.service.StorageService - Node /127.0.0.1 state jump to shutdown
[StorageServiceShutdownHook] INFO org.apache.cassandra.net.MessagingService - Waiting for messaging service to quiesce
[ACCEPT-/127.0.0.1] INFO org.apache.cassandra.net.MessagingService - MessagingService has terminated the accept() thread
[StorageServiceShutdownHook] INFO org.apache.cassandra.hints.HintsService - Paused hints dispatch
[StorageServiceShutdownHook] INFO org.apache.cassandra.hints.HintsService - Paused hints dispatch

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.ElasticsearchClientTest
Elasticsearch starting node = es.ycsb.cluster
Elasticsearch node path.home = /tmp/junit8222518426794489267
Elasticsearch Remote Mode = false
Nov 27, 2020 2:02:44 AM org.elasticsearch.node.Node <init>
INFO: [Gemini] version[2.4.0], pid[4405], build[ce9f0c7/2016-08-29T09:14:17Z]
Nov 27, 2020 2:02:44 AM org.elasticsearch.node.Node <init>
INFO: [Gemini] initializing ...
Nov 27, 2020 2:02:44 AM org.elasticsearch.plugins.PluginsService <init>
INFO: [Gemini] modules [], plugins [], sites []
Nov 27, 2020 2:02:44 AM org.elasticsearch.env.NodeEnvironment maybeLogPathDetails
INFO: [Gemini] using [1] data paths, mounts [[/ (overlay)]], net usable_space [85.8tb], net total_space [90.9tb], spins? [possibly], types [overlay]
Nov 27, 2020 2:02:44 AM org.elasticsearch.env.NodeEnvironment maybeLogHeapDetails
INFO: [Gemini] heap size [1.7gb], compressed ordinary object pointers [true]
Nov 27, 2020 2:02:44 AM org.elasticsearch.env.NodeEnvironment maybeWarnFileDescriptors
WARNING: [Gemini] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
Nov 27, 2020 2:02:45 AM org.elasticsearch.node.Node <init>
INFO: [Gemini] initialized
Nov 27, 2020 2:02:45 AM org.elasticsearch.node.Node start
INFO: [Gemini] starting ...
Nov 27, 2020 2:02:45 AM org.elasticsearch.transport.TransportService doStart
INFO: [Gemini] publish_address {local[1]}, bound_addresses {local[1]}
Nov 27, 2020 2:02:45 AM org.elasticsearch.discovery.DiscoveryService doStart
INFO: [Gemini] es.ycsb.cluster/IypRVELzTKKL6X4-hVnAXQ
Nov 27, 2020 2:02:45 AM org.elasticsearch.cluster.service.InternalClusterService runTasksForExecutor
INFO: [Gemini] new_master {Gemini}{IypRVELzTKKL6X4-hVnAXQ}{local}{local[1]}{local=true}, reason: local-disco-initial_connect(master)
Nov 27, 2020 2:02:45 AM org.elasticsearch.gateway.GatewayService$GatewayRecoveryListener$1 clusterStateProcessed
INFO: [Gemini] recovered [0] indices into cluster_state
Nov 27, 2020 2:02:45 AM org.elasticsearch.http.HttpServer doStart
INFO: [Gemini] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}
Nov 27, 2020 2:02:45 AM org.elasticsearch.node.Node start
INFO: [Gemini] started
Nov 27, 2020 2:02:46 AM org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$1 execute
INFO: [Gemini] [es.ycsb] creating index, cause [api], templates [], shards [1]/[0], mappings []
Nov 27, 2020 2:02:46 AM org.elasticsearch.cluster.routing.allocation.AllocationService logClusterHealthStateChange
INFO: [Gemini] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[es.ycsb][0]] ...]).
Nov 27, 2020 2:02:46 AM org.elasticsearch.cluster.metadata.MetaDataMappingService$PutMappingExecutor applyRequest
INFO: [Gemini] [es.ycsb] create_mapping [MOCK_TABLE]
Nov 27, 2020 2:02:46 AM org.elasticsearch.node.Node stop
INFO: [Gemini] stopping ...
Nov 27, 2020 2:02:47 AM org.elasticsearch.node.Node stop
INFO: [Gemini] stopped
Nov 27, 2020 2:02:47 AM org.elasticsearch.node.Node close
INFO: [Gemini] closing ...
Nov 27, 2020 2:02:47 AM org.elasticsearch.node.Node close
INFO: [Gemini] closed
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.344 sec

Results :

Tests run: 5, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.HBaseClient10Test
2020/11/27 02:02:50 WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Formatting using clusterid: testClusterID
2020/11/27 02:02:51 WARN  org.apache.hadoop.metrics2.impl.MetricsConfig  - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2020/11/27 02:02:51 WARN  org.apache.hadoop.security.authentication.server.AuthenticationFilter  - 'signature.secret' configuration not set, using a random value as secret
2020/11/27 02:02:53 WARN  org.apache.hadoop.hbase.ZNodeClearer  - Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2020/11/27 02:02:54 WARN  org.apache.hadoop.hbase.HTableDescriptor  - Use addCoprocessor* methods to add a coprocessor instead
2020/11/27 02:02:55 WARN  org.apache.zookeeper.server.persistence.FileTxnLog  - fsync-ing the write ahead log in SyncThread:0 took 1607ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2020/11/27 02:02:56 WARN  org.apache.hadoop.hbase.ZNodeClearer  - Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
2020/11/27 02:02:57 WARN  org.apache.zookeeper.server.NIOServerCnxn  - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x17607705cc20007, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:748)
2020/11/27 02:03:03 WARN  org.apache.zookeeper.server.persistence.FileTxnLog  - fsync-ing the write ahead log in SyncThread:0 took 1477ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2020/11/27 02:03:03 WARN  org.apache.hadoop.hbase.master.TableLockManager  - Could not delete the znode for table locks because NOTEMPTY: /hbase/table-lock/usertable
2020/11/27 02:03:06 WARN  org.apache.zookeeper.server.persistence.FileTxnLog  - fsync-ing the write ahead log in SyncThread:0 took 1830ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2020/11/27 02:03:07 WARN  org.apache.zookeeper.server.persistence.FileTxnLog  - fsync-ing the write ahead log in SyncThread:0 took 1479ms which will adversely effect operation latency. See the ZooKeeper troubleshooting guide
2020/11/27 02:03:16 WARN  org.apache.zookeeper.server.NIOServerCnxn  - caught end of stream exception
EndOfStreamException: Unable to read additional data from client sessionid 0x17607705cc20005, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:208)
	at java.lang.Thread.run(Thread.java:748)
2020/11/27 02:03:17 WARN  org.apache.hadoop.hdfs.server.datanode.DirectoryScanner  - DirectoryScanner: shutdown has been called
2020/11/27 02:03:17 WARN  org.apache.hadoop.hdfs.server.datanode.DataNode  - BPOfferService for Block pool BP-1999287910-172.17.0.8-1606442571251 (Datanode Uuid f2d0aed3-35ce-48de-85e3-fa759fe149ea) service to localhost/127.0.0.1:37619 interrupted
2020/11/27 02:03:17 WARN  org.apache.hadoop.hdfs.server.datanode.DataNode  - Ending block pool service for: Block pool BP-1999287910-172.17.0.8-1606442571251 (Datanode Uuid f2d0aed3-35ce-48de-85e3-fa759fe149ea) service to localhost/127.0.0.1:37619
2020/11/27 02:03:17 WARN  org.apache.hadoop.hdfs.server.blockmanagement.DecommissionManager  - Monitor interrupted: java.lang.InterruptedException: sleep interrupted
Tests run: 5, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 27.454 sec

Results :

Tests run: 5, Failures: 0, Errors: 0, Skipped: 1


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.JdbcDBClientTest
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:1, fetchSize: -1
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:10, fetchSize: -1
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:1, fetchSize: -1
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:10, fetchSize: -1
Adding shard node URL: jdbc:hsqldb:mem:ycsb
Using shards: 1, batchSize:1, fetchSize: -1
Tests run: 7, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.426 sec

Results :

Tests run: 7, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.OptionsSupportTest
Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.05 sec
Running com.yahoo.ycsb.db.AsyncMongoDbClientTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.012 sec
Running com.yahoo.ycsb.db.MongoDbClientTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0 sec

Results :

Tests run: 6, Failures: 0, Errors: 0, Skipped: 2


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.OrientDBClientTest
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 320
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 2147483647
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 4096
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 1000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2020-11-27 02:03:20 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
Nov 27, 2020 2:03:21 AM com.orientechnologies.common.log.OLogManager log
INFO: OrientDB auto-config DISKCACHE=1,820MB (heap=1,820MB direct=1,820MB os=192,081MB), assuming maximum direct memory size equals to maximum JVM heap size
Nov 27, 2020 2:03:21 AM com.orientechnologies.common.log.OLogManager log
WARNING: MaxDirectMemorySize JVM option is not set or has invalid value, that may cause out of memory errors. Please set the -XX:MaxDirectMemorySize=192081m option when you start the JVM.
2020-11-27 02:03:21 INFO  OrientDBClient:115 - OrientDB database not found, creating fresh db
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 320
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 1908408320
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 1820
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 10000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2020-11-27 02:03:23 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 320
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 1908408320
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 1820
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 10000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2020-11-27 02:03:23 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 320
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 1908408320
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 1820
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 10000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2020-11-27 02:03:23 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
OrientDB 2.2.10 configuration dump:
- ENVIRONMENT
  + environment.dumpCfgAtStartup = false
  + environment.concurrent = true
  + environment.lockManager.concurrency.level = 320
  + environment.allowJVMShutdown = true
- SCRIPT
  + script.pool.maxSize = 20
- MEMORY
  + memory.useUnsafe = true
  + memory.chunk.size = 1908408320
  + memory.directMemory.safeMode = true
  + memory.directMemory.trackMode = false
  + memory.directMemory.onlyAlignedMemoryAccess = true
- JVM
  + jvm.gc.delayForOptimize = 600
- STORAGE
  + storage.openFiles.limit = 512
  + storage.componentsLock.cache = 10000
  + storage.diskCache.pinnedPages = 20
  + storage.diskCache.bufferSize = 1820
  + storage.diskCache.writeCachePart = 15
  + storage.diskCache.writeCachePageTTL = 86400
  + storage.diskCache.writeCachePageFlushInterval = 25
  + storage.diskCache.writeCacheFlushInactivityInterval = 60000
  + storage.diskCache.writeCacheFlushLockTimeout = -1
  + storage.diskCache.diskFreeSpaceCheckInterval = 5
  + storage.diskCache.diskFreeSpaceCheckIntervalInPages = 2048
  + storage.diskCache.keepState = true
  + storage.configuration.syncOnUpdate = true
  + storage.compressionMethod = nothing
  + storage.encryptionMethod = nothing
  + storage.encryptionKey = <hidden>
  + storage.makeFullCheckpointAfterCreate = false
  + storage.makeFullCheckpointAfterOpen = true
  + storage.makeFullCheckpointAfterClusterCreate = true
  + storage.trackChangedRecordsInWAL = false
  + storage.useWAL = true
  + storage.wal.syncOnPageFlush = true
  + storage.wal.cacheSize = 3000
  + storage.wal.fileAutoCloseInterval = 10
  + storage.wal.maxSegmentSize = 128
  + storage.wal.maxSize = 4096
  + storage.wal.commitTimeout = 1000
  + storage.wal.shutdownTimeout = 10000
  + storage.wal.fuzzyCheckpointInterval = 300
  + storage.wal.reportAfterOperationsDuringRestore = 10000
  + storage.wal.restore.batchSize = 10000
  + storage.wal.readCacheSize = 1000
  + storage.wal.fuzzyCheckpointShutdownWait = 600
  + storage.wal.fullCheckpointShutdownTimeout = 600
  + storage.wal.path = null
  + storage.diskCache.pageSize = 64
  + storage.diskCache.diskFreeSpaceLimit = 256
  + storage.lowestFreeListBound = 16
  + storage.lockTimeout = 0
  + storage.record.lockTimeout = 2000
  + storage.useTombstones = false
- RECORD
  + record.downsizing.enabled = true
- OBJECT
  + object.saveOnlyDirty = false
- DB
  + db.pool.min = 1
  + db.pool.max = 100
  + db.pool.idleTimeout = 0
  + db.pool.idleCheckDelay = 0
  + db.mvcc.throwfast = false
  + db.validation = true
- NONTX
  + nonTX.recordUpdate.synch = false
  + nonTX.clusters.sync.immediately = manindex
- TX
  + tx.trackAtomicOperations = false
- INDEX
  + index.embeddedToSbtreeBonsaiThreshold = 40
  + index.sbtreeBonsaiToEmbeddedThreshold = -1
- HASHTABLE
  + hashTable.slitBucketsBuffer.length = 1500
- INDEX
  + index.auto.synchronousAutoRebuild = true
  + index.auto.lazyUpdates = 10000
  + index.flushAfterCreate = true
  + index.manual.lazyUpdates = 1
  + index.durableInNonTxMode = true
  + index.ignoreNullValuesDefault = false
  + index.txMode = FULL
  + index.cursor.prefetchSize = 500000
- SBTREE
  + sbtree.maxDepth = 64
  + sbtree.maxKeySize = 10240
  + sbtree.maxEmbeddedValueSize = 40960
- SBTREEBONSAI
  + sbtreebonsai.bucketSize = 2
  + sbtreebonsai.linkBagCache.size = 100000
  + sbtreebonsai.linkBagCache.evictionSize = 1000
  + sbtreebonsai.freeSpaceReuseTrigger = 0.5
- RIDBAG
  + ridBag.embeddedDefaultSize = 4
  + ridBag.embeddedToSbtreeBonsaiThreshold = 40
  + ridBag.sbtreeBonsaiToEmbeddedToThreshold = -1
- COLLECTIONS
  + collections.preferSBTreeSet = false
- FILE
  + file.trackFileClose = false
  + file.lock = true
  + file.deleteDelay = 10
  + file.deleteRetry = 50
- SECURITY
  + security.userPasswordSaltIterations = 65536
  + security.userPasswordSaltCacheSize = 500
  + security.userPasswordDefaultAlgorithm = PBKDF2WithHmacSHA256
- NETWORK
  + network.maxConcurrentSessions = 1000
  + network.socketBufferSize = 32768
  + network.lockTimeout = 15000
  + network.socketTimeout = 15000
  + network.requestTimeout = 3600000
  + network.retry = 5
  + network.retryDelay = 500
  + network.binary.loadBalancing.enabled = false
  + network.binary.loadBalancing.timeout = 2000
  + network.binary.maxLength = 16384
  + network.binary.readResponse.maxTimes = 20
  + network.binary.debug = false
  + network.http.installDefaultCommands = true
  + network.http.serverInfo = OrientDB Server v.2.2.10
  + network.http.maxLength = 1000000
  + network.http.streaming = true
  + network.http.charset = utf-8
  + network.http.jsonResponseError = true
  + network.http.jsonp = false
  + network.http.sessionExpireTimeout = 300
  + network.http.useToken = false
  + network.token.secretyKey = 
  + network.token.encriptionAlgorithm = HmacSHA256
  + network.token.expireTimeout = 60
- PROFILER
  + profiler.enabled = false
  + profiler.config = null
  + profiler.autoDump.interval = 0
  + profiler.maxValues = 200
- SEQUENCE
  + sequence.maxRetry = 100
  + sequence.retryDelay = 200
- STORAGEPROFILER
  + storageProfiler.intervalBetweenSnapshots = 100
  + storageProfiler.cleanUpInterval = 5000
- LOG
  + log.console.level = info
  + log.file.level = info
- CLASS
  + class.minimumClusters = 0
- LOG
  + log.console.ansi = auto
- CACHE
  + cache.local.impl = com.orientechnologies.orient.core.cache.ORecordCacheWeakRefs
- COMMAND
  + command.timeout = 0
  + command.cache.enabled = false
  + command.cache.evictStrategy = PER_CLUSTER
  + command.cache.minExecutionTime = 10
  + command.cache.maxResultsetSize = 500
- QUERY
  + query.parallelAuto = false
  + query.parallelMinimumRecords = 300000
  + query.parallelResultQueueSize = 20000
  + query.scanPrefetchPages = 20
  + query.scanBatchSize = 1000
  + query.scanThresholdTip = 50000
  + query.limitThresholdTip = 10000
  + query.live.support = true
- STATEMENT
  + statement.cacheSize = 100
- SQL
  + sql.graphConsistencyMode = tx
- CLIENT
  + client.channel.maxPool = 100
  + client.connectionPool.waitTimeout = 5000
  + client.channel.dbReleaseWaitTimeout = 10000
  + client.ssl.enabled = false
  + client.ssl.keyStore = null
  + client.ssl.keyStorePass = null
  + client.ssl.trustStore = null
  + client.ssl.trustStorePass = null
- SERVER
  + server.openAllDatabasesAtStartup = false
  + server.channel.cleanDelay = 5000
  + server.cache.staticFile = false
  + server.log.dumpClientExceptionLevel = FINE
  + server.log.dumpClientExceptionFullStackTrace = false
- DISTRIBUTED
  + distributed.crudTaskTimeout = 3000
  + distributed.commandTaskTimeout = 120000
  + distributed.commandQuickTaskTimeout = 5000
  + distributed.commandLongTaskTimeout = 86400000
  + distributed.deployDbTaskTimeout = 1200000
  + distributed.deployChunkTaskTimeout = 15000
  + distributed.deployDbTaskCompression = 7
  + distributed.asynchQueueSize = 0
  + distributed.asynchResponsesTimeout = 15000
  + distributed.purgeResponsesTimerDelay = 15000
  + distributed.conflictResolverRepairerChain = majority,content,version
  + distributed.conflictResolverRepairerCheckEvery = 5000
  + distributed.conflictResolverRepairerBatch = 100
  + distributed.txAliveTimeout = 30000
  + distributed.requestChannels = 1
  + distributed.responseChannels = 1
  + distributed.heartbeatTimeout = 10000
  + distributed.checkHealthCanOfflineServer = false
  + distributed.checkHealthEvery = 10000
  + distributed.autoRemoveOfflineServers = -1
  + distributed.publishNodeStatusEvery = 5000
  + distributed.localQueueSize = 10000
  + distributed.dbWorkerThreads = 8
  + distributed.queueMaxSize = 10000
  + distributed.backupDirectory = ../backup/databases
  + distributed.concurrentTxMaxAutoRetry = 10
  + distributed.atomicLockTimeout = 300
  + distributed.concurrentTxAutoRetryDelay = 100
- DB
  + db.document.serializer = ORecordSerializerBinary
- CLIENT
  + client.krb5.config = null
  + client.krb5.ccname = null
  + client.krb5.ktname = null
  + client.credentialinterceptor = null
- SECURITY
  + security.createDefaultUsers = true
- SERVER
  + server.security.file = null
- JNA
  + jna.disable.system.library = true
- DISTRIBUTED
  + distributed.queueTimeout = 500000
- DB
  + db.makeFullCheckpointOnIndexChange = true
  + db.makeFullCheckpointOnSchemaChange = true
- CLIENT
  + client.session.tokenBased = true
- OAUTH2
  + oauth2.secretkey = 
- STORAGE
  + storage.cluster.usecrc32 = false
- LAZYSET
  + lazyset.workOnStream = true
- DB
  + db.mvcc = true
  + db.use.distributedVersion = false
- MVRBTREE
  + mvrbtree.timeout = 0
  + mvrbtree.nodePageSize = 256
  + mvrbtree.loadFactor = 0.7
  + mvrbtree.optimizeThreshold = 100000
  + mvrbtree.entryPoints = 64
  + mvrbtree.optimizeEntryPointsFactor = 1.0
  + mvrbtree.entryKeysInMemory = false
  + mvrbtree.entryValuesInMemory = false
  + mvrbtree.ridBinaryThreshold = -1
  + mvrbtree.ridNodePageSize = 64
  + mvrbtree.ridNodeSaveMemory = false
- TX
  + tx.commit.synch = false
  + tx.autoRetry = 1
  + tx.log.fileType = classic
  + tx.log.synch = false
  + tx.useLog = true
- INDEX
  + index.auto.rebuildAfterNotSoftClose = true
- CLIENT
  + client.channel.minPool = 1
- STORAGE
  + storage.keepOpen = true
- CACHE
  + cache.local.enabled = true
2020-11-27 02:03:23 INFO  OrientDBClient:94 - OrientDB loading database url = memory:test
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 2.641 sec

Results :

Tests run: 5, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.RadosClientTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.191 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 1


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.webservice.rest.RestClientTest
Nov 27, 2020 2:03:25 AM org.apache.coyote.AbstractProtocol init
INFO: Initializing ProtocolHandler ["http-nio-8080"]
Nov 27, 2020 2:03:25 AM org.apache.tomcat.util.net.NioSelectorPool getSharedSelector
INFO: Using a shared selector for servlet write/read
Nov 27, 2020 2:03:25 AM org.apache.catalina.core.StandardService startInternal
INFO: Starting service Tomcat
Nov 27, 2020 2:03:25 AM org.apache.catalina.core.StandardEngine startInternal
INFO: Starting Servlet Engine: Apache Tomcat/8.0.28
Nov 27, 2020 2:03:26 AM org.apache.catalina.startup.ContextConfig getDefaultWebXmlFragment
INFO: No global web.xml found
Nov 27, 2020 2:03:26 AM org.apache.jasper.servlet.TldScanner scanJars
INFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
Nov 27, 2020 2:03:26 AM org.apache.coyote.AbstractProtocol start
INFO: Starting ProtocolHandler ["http-nio-8080"]
Nov 27, 2020 2:03:27 AM org.glassfish.jersey.server.ApplicationHandler initialize
INFO: Initiating Jersey application, version Jersey: 2.6 2014-02-18 21:52:53...
Tests run: 17, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 3.069 sec
Running com.yahoo.ycsb.webservice.rest.IntegrationTest
Nov 27, 2020 2:03:28 AM org.apache.coyote.AbstractProtocol init
INFO: Initializing ProtocolHandler ["http-nio-8081"]
Nov 27, 2020 2:03:28 AM org.apache.tomcat.util.net.NioSelectorPool getSharedSelector
INFO: Using a shared selector for servlet write/read
Nov 27, 2020 2:03:28 AM org.apache.catalina.core.StandardService startInternal
INFO: Starting service Tomcat
Nov 27, 2020 2:03:28 AM org.apache.catalina.core.StandardEngine startInternal
INFO: Starting Servlet Engine: Apache Tomcat/8.0.28
Nov 27, 2020 2:03:28 AM org.apache.catalina.startup.ContextConfig getDefaultWebXmlFragment
INFO: No global web.xml found
Nov 27, 2020 2:03:28 AM org.apache.jasper.servlet.TldScanner scanJars
INFO: At least one JAR was scanned for TLDs yet contained no TLDs. Enable debug logging for this logger for a complete list of JARs that were scanned but no TLDs were found in them. Skipping unneeded JARs during scanning can improve startup time and JSP compilation time.
Nov 27, 2020 2:03:28 AM org.apache.coyote.AbstractProtocol start
INFO: Starting ProtocolHandler ["http-nio-8081"]
Command line: -target 1 -t -P /home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.insert=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.update=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.delete=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p exportfile=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=0.0 -p deleteproportion=1.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Nov 27, 2020 2:03:30 AM org.glassfish.jersey.server.ApplicationHandler initialize
INFO: Initiating Jersey application, version Jersey: 2.6 2014-02-18 21:52:53...
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.insert=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.update=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.delete=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p exportfile=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=0.0 -p deleteproportion=1.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.insert=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.update=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.delete=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p exportfile=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=0.0 -p deleteproportion=0.0 -p insertproportion=1.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.insert=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.update=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.delete=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p exportfile=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=0.0 -p deleteproportion=0.0 -p insertproportion=1.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.insert=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.update=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.delete=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p exportfile=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=1.0 -p updateproportion=0.0 -p deleteproportion=0.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.insert=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.update=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.delete=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p exportfile=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=1.0 -p updateproportion=0.0 -p deleteproportion=0.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.insert=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.update=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p url.trace.delete=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/error_trace.txt -p exportfile=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=1.0 -p deleteproportion=0.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Command line: -target 1 -t -P /home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/workload_rest -p url.prefix=http://127.0.0.1:8081/webService/rest/resource/ -p url.trace.read=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.insert=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.update=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p url.trace.delete=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/trace.txt -p exportfile=/home/travis/build/passed/brianfrankcooper/YCSB/rest/target/test-classes/results.txt -p readproportion=0.0 -p updateproportion=1.0 -p deleteproportion=0.0 -p insertproportion=0.0YCSB Client 0.13.0-RC1

Loading workload...
Starting test.
Maximum execution time specified as: 720 secs
DBWrapper: report latency for each error is false and specific error codes to track for latency are: []
Could not wait until max specified time, TerminatorThread interrupted.
Nov 27, 2020 2:03:40 AM org.apache.coyote.AbstractProtocol pause
INFO: Pausing ProtocolHandler ["http-nio-8081"]
Nov 27, 2020 2:03:40 AM org.apache.catalina.core.StandardService stopInternal
INFO: Stopping service Tomcat
Nov 27, 2020 2:03:41 AM org.apache.coyote.AbstractProtocol stop
INFO: Stopping ProtocolHandler ["http-nio-8081"]
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.527 sec

Results :

Tests run: 25, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.riak.RiakKVClientTest
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
Tests run: 1, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 0.413 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 1


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.solr.SolrClientTest
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.577 sec
Running com.yahoo.ycsb.db.solr.SolrClientCloudTest
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:43757/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:43757/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:43757/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:43757/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:43757/solr
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.683 sec

Results :

Tests run: 10, Failures: 0, Errors: 0, Skipped: 0


-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Running com.yahoo.ycsb.db.solr6.SolrClientTest
2020/11/27 02:04:43 ERROR org.apache.solr.servlet.StartupLoggingUtils  - Missing Java Option solr.log.dir. Logging may be missing or incomplete.
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Solr Cloud Mode = false
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.678 sec
Running com.yahoo.ycsb.db.solr6.SolrClientCloudTest
2020/11/27 02:05:17 ERROR org.apache.solr.servlet.StartupLoggingUtils  - Missing Java Option solr.log.dir. Logging may be missing or incomplete.
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:38193/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:38193/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:38193/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:38193/solr
Solr Cloud Mode = true
Solr Zookeeper Remote Hosts = 127.0.0.1:38193/solr
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.085 sec

Results :

Tests run: 10, Failures: 0, Errors: 0, Skipped: 0


travis_time:end:16f43aae:start=1606442436543295968,finish=1606442744646786412,duration=308103490444[0K
[32;1mThe command "mvn test -Dhttps.protocols=TLSv1.2 -q" exited with 0.[0m

Done. Your build exited with 0.
