travis_fold:start:system_info[0K[33;1mBuild system information[0m
Build language: java
Build group: stable
Build dist: trusty
Build id: ''
Job id: ''
[34m[1mBuild image provisioning date and time[0m
Tue Dec  5 20:11:19 UTC 2017
[34m[1mOperating System Details[0m
Distributor ID:	Ubuntu
Description:	Ubuntu 14.04.5 LTS
Release:	14.04
Codename:	trusty
[34m[1mCookbooks Version[0m
7c2c6a6 https://github.com/travis-ci/travis-cookbooks/tree/7c2c6a6
[34m[1mgit version[0m
git version 2.15.1
[34m[1mbash version[0m
GNU bash, version 4.3.11(1)-release (x86_64-pc-linux-gnu)
[34m[1mgcc version[0m
gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[34m[1mdocker version[0m
Client:
 Version:      17.09.0-ce
 API version:  1.32
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:39:28 2017
 OS/Arch:      linux/amd64
[34m[1mclang version[0m
clang version 5.0.0 (tags/RELEASE_500/final)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/local/clang-5.0.0/bin
[34m[1mjq version[0m
jq-1.5
[34m[1mbats version[0m
Bats 0.4.0
[34m[1mshellcheck version[0m
0.4.6
[34m[1mshfmt version[0m
v2.0.0
[34m[1mccache version[0m
ccache version 3.1.9

Copyright (C) 2002-2007 Andrew Tridgell
Copyright (C) 2009-2011 Joel Rosdahl

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; either version 3 of the License, or (at your option) any later
version.
[34m[1mcmake version[0m
cmake version 3.9.2

CMake suite maintained and supported by Kitware (kitware.com/cmake).
[34m[1mheroku version[0m
heroku-cli/6.14.39-addc925 (linux-x64) node-v9.2.0
[34m[1mimagemagick version[0m
Version: ImageMagick 6.7.7-10 2017-07-31 Q16 http://www.imagemagick.org
[34m[1mmd5deep version[0m
4.2
[34m[1mmercurial version[0m
Mercurial Distributed SCM (version 4.2.2)
(see https://mercurial-scm.org for more information)

Copyright (C) 2005-2017 Matt Mackall and others
This is free software; see the source for copying conditions. There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
[34m[1mmysql version[0m
mysql  Ver 14.14 Distrib 5.6.33, for debian-linux-gnu (x86_64) using  EditLine wrapper
[34m[1mopenssl version[0m
OpenSSL 1.0.1f 6 Jan 2014
[34m[1mpacker version[0m
Packer v1.0.2

Your version of Packer is out of date! The latest version
is 1.1.2. You can update by downloading from www.packer.io
[34m[1mpostgresql client version[0m
psql (PostgreSQL) 9.6.6
[34m[1mragel version[0m
Ragel State Machine Compiler version 6.8 Feb 2013
Copyright (c) 2001-2009 by Adrian Thurston
[34m[1msubversion version[0m
svn, version 1.8.8 (r1568071)
   compiled Aug 10 2017, 17:20:39 on x86_64-pc-linux-gnu

Copyright (C) 2013 The Apache Software Foundation.
This software consists of contributions made by many people;
see the NOTICE file for more information.
Subversion is open source software, see http://subversion.apache.org/

The following repository access (RA) modules are available:

* ra_svn : Module for accessing a repository using the svn network protocol.
  - with Cyrus SASL authentication
  - handles 'svn' scheme
* ra_local : Module for accessing a repository on local disk.
  - handles 'file' scheme
* ra_serf : Module for accessing a repository via WebDAV protocol using serf.
  - using serf 1.3.3
  - handles 'http' scheme
  - handles 'https' scheme

[34m[1msudo version[0m
Sudo version 1.8.9p5
Configure options: --prefix=/usr -v --with-all-insults --with-pam --with-fqdn --with-logging=syslog --with-logfac=authpriv --with-env-editor --with-editor=/usr/bin/editor --with-timeout=15 --with-password-timeout=0 --with-passprompt=[sudo] password for %p:  --without-lecture --with-tty-tickets --disable-root-mailer --enable-admin-flag --with-sendmail=/usr/sbin/sendmail --with-timedir=/var/lib/sudo --mandir=/usr/share/man --libexecdir=/usr/lib/sudo --with-sssd --with-sssd-lib=/usr/lib/x86_64-linux-gnu --with-selinux
Sudoers policy plugin version 1.8.9p5
Sudoers file grammar version 43

Sudoers path: /etc/sudoers
Authentication methods: 'pam'
Syslog facility if syslog is being used for logging: authpriv
Syslog priority to use when user authenticates successfully: notice
Syslog priority to use when user authenticates unsuccessfully: alert
Send mail if the user is not in sudoers
Use a separate timestamp for each user/tty combo
Lecture user the first time they run sudo
Root may run sudo
Allow some information gathering to give useful error messages
Require fully-qualified hostnames in the sudoers file
Visudo will honor the EDITOR environment variable
Set the LOGNAME and USER environment variables
Length at which to wrap log file lines (0 for no wrap): 80
Authentication timestamp timeout: 15.0 minutes
Password prompt timeout: 0.0 minutes
Number of tries to enter a password: 3
Umask to use or 0777 to use user's: 022
Path to mail program: /usr/sbin/sendmail
Flags for mail program: -t
Address to send mail to: root
Subject line for mail messages: *** SECURITY information for %h ***
Incorrect password message: Sorry, try again.
Path to authentication timestamp dir: /var/lib/sudo
Default password prompt: [sudo] password for %p: 
Default user to run commands as: root
Value to override user's $PATH with: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
Path to the editor for use by visudo: /usr/bin/editor
When to require a password for 'list' pseudocommand: any
When to require a password for 'verify' pseudocommand: all
File descriptors >= 3 will be closed before executing a command
Environment variables to check for sanity:
	TZ
	TERM
	LINGUAS
	LC_*
	LANGUAGE
	LANG
	COLORTERM
Environment variables to remove:
	RUBYOPT
	RUBYLIB
	PYTHONUSERBASE
	PYTHONINSPECT
	PYTHONPATH
	PYTHONHOME
	TMPPREFIX
	ZDOTDIR
	READNULLCMD
	NULLCMD
	FPATH
	PERL5DB
	PERL5OPT
	PERL5LIB
	PERLLIB
	PERLIO_DEBUG 
	JAVA_TOOL_OPTIONS
	SHELLOPTS
	GLOBIGNORE
	PS4
	BASH_ENV
	ENV
	TERMCAP
	TERMPATH
	TERMINFO_DIRS
	TERMINFO
	_RLD*
	LD_*
	PATH_LOCALE
	NLSPATH
	HOSTALIASES
	RES_OPTIONS
	LOCALDOMAIN
	CDPATH
	IFS
Environment variables to preserve:
	JAVA_HOME
	TRAVIS
	CI
	DEBIAN_FRONTEND
	XAUTHORIZATION
	XAUTHORITY
	PS2
	PS1
	PATH
	LS_COLORS
	KRB5CCNAME
	HOSTNAME
	HOME
	DISPLAY
	COLORS
Locale to use while parsing sudoers: C
Directory in which to store input/output logs: /var/log/sudo-io
File in which to store the input/output log: %{seq}
Add an entry to the utmp/utmpx file when allocating a pty
PAM service name to use
PAM service name to use for login shells
Create a new PAM session for the command to run in
Maximum I/O log sequence number: 0

Local IP address and netmask pairs:
	172.17.0.2/255.255.0.0

Sudoers I/O plugin version 1.8.9p5
[34m[1mgzip version[0m
gzip 1.6
Copyright (C) 2007, 2010, 2011 Free Software Foundation, Inc.
Copyright (C) 1993 Jean-loup Gailly.
This is free software.  You may redistribute copies of it under the terms of
the GNU General Public License <http://www.gnu.org/licenses/gpl.html>.
There is NO WARRANTY, to the extent permitted by law.

Written by Jean-loup Gailly.
[34m[1mzip version[0m
Copyright (c) 1990-2008 Info-ZIP - Type 'zip "-L"' for software license.
This is Zip 3.0 (July 5th 2008), by Info-ZIP.
Currently maintained by E. Gordon.  Please send bug reports to
the authors using the web page at www.info-zip.org; see README for details.

Latest sources and executables are at ftp://ftp.info-zip.org/pub/infozip,
as of above date; see http://www.info-zip.org/ for other sites.

Compiled with gcc 4.8.2 for Unix (Linux ELF) on Oct 21 2013.

Zip special compilation options:
	USE_EF_UT_TIME       (store Universal Time)
	BZIP2_SUPPORT        (bzip2 library version 1.0.6, 6-Sept-2010)
	    bzip2 code and library copyright (c) Julian R Seward
	    (See the bzip2 license for terms of use)
	SYMLINK_SUPPORT      (symbolic links supported)
	LARGE_FILE_SUPPORT   (can read and write large files on file system)
	ZIP64_SUPPORT        (use Zip64 to store large files in archives)
	UNICODE_SUPPORT      (store and read UTF-8 Unicode paths)
	STORE_UNIX_UIDs_GIDs (store UID/GID sizes/values using new extra field)
	UIDGID_NOT_16BIT     (old Unix 16-bit UID/GID extra field not used)
	[encryption, version 2.91 of 05 Jan 2007] (modified for Zip 3)

Encryption notice:
	The encryption code of this program is not copyrighted and is
	put in the public domain.  It was originally written in Europe
	and, to the best of our knowledge, can be freely distributed
	in both source and object forms from any country, including
	the USA under License Exception TSU of the U.S. Export
	Administration Regulations (section 740.13(e)) of 6 June 2002.

Zip environment options:
             ZIP:  [none]
          ZIPOPT:  [none]
[34m[1mvim version[0m
VIM - Vi IMproved 7.4 (2013 Aug 10, compiled Nov 24 2016 16:43:18)
Included patches: 1-52
Extra patches: 8.0.0056
Modified by pkg-vim-maintainers@lists.alioth.debian.org
Compiled by buildd@
Huge version without GUI.  Features included (+) or not (-):
+acl             +farsi           +mouse_netterm   +syntax
+arabic          +file_in_path    +mouse_sgr       +tag_binary
+autocmd         +find_in_path    -mouse_sysmouse  +tag_old_static
-balloon_eval    +float           +mouse_urxvt     -tag_any_white
-browse          +folding         +mouse_xterm     -tcl
++builtin_terms  -footer          +multi_byte      +terminfo
+byte_offset     +fork()          +multi_lang      +termresponse
+cindent         +gettext         -mzscheme        +textobjects
-clientserver    -hangul_input    +netbeans_intg   +title
-clipboard       +iconv           +path_extra      -toolbar
+cmdline_compl   +insert_expand   -perl            +user_commands
+cmdline_hist    +jumplist        +persistent_undo +vertsplit
+cmdline_info    +keymap          +postscript      +virtualedit
+comments        +langmap         +printer         +visual
+conceal         +libcall         +profile         +visualextra
+cryptv          +linebreak       +python          +viminfo
+cscope          +lispindent      -python3         +vreplace
+cursorbind      +listcmds        +quickfix        +wildignore
+cursorshape     +localmap        +reltime         +wildmenu
+dialog_con      -lua             +rightleft       +windows
+diff            +menu            -ruby            +writebackup
+digraphs        +mksession       +scrollbind      -X11
-dnd             +modify_fname    +signs           -xfontset
-ebcdic          +mouse           +smartindent     -xim
+emacs_tags      -mouseshape      -sniff           -xsmp
+eval            +mouse_dec       +startuptime     -xterm_clipboard
+ex_extra        +mouse_gpm       +statusline      -xterm_save
+extra_search    -mouse_jsbterm   -sun_workshop    -xpm
   system vimrc file: "$VIM/vimrc"
     user vimrc file: "$HOME/.vimrc"
 2nd user vimrc file: "~/.vim/vimrc"
      user exrc file: "$HOME/.exrc"
  fall-back for $VIM: "/usr/share/vim"
Compilation: gcc -c -I. -Iproto -DHAVE_CONFIG_H     -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1      
Linking: gcc   -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,--as-needed -o vim        -lm -ltinfo -lnsl  -lselinux  -lacl -lattr -lgpm -ldl    -L/usr/lib/python2.7/config-x86_64-linux-gnu -lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions      
[34m[1miptables version[0m
iptables v1.4.21
[34m[1mcurl version[0m
curl 7.35.0 (x86_64-pc-linux-gnu) libcurl/7.35.0 OpenSSL/1.0.1f zlib/1.2.8 libidn/1.28 librtmp/2.3
[34m[1mwget version[0m
GNU Wget 1.15 built on linux-gnu.
[34m[1mrsync version[0m
rsync  version 3.1.0  protocol version 31
[34m[1mgimme version[0m
v1.2.0
[34m[1mnvm version[0m
0.33.6
[34m[1mperlbrew version[0m
/home/travis/perl5/perlbrew/bin/perlbrew  - App::perlbrew/0.80
[34m[1mphpenv version[0m
rbenv 1.1.1-25-g6aa70b6
[34m[1mrvm version[0m
rvm 1.29.3 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io]
[34m[1mdefault ruby version[0m
ruby 2.4.1p111 (2017-03-22 revision 58053) [x86_64-linux]
[34m[1mCouchDB version[0m
couchdb 1.6.1
[34m[1mElasticSearch version[0m
5.5.0
[34m[1mInstalled Firefox version[0m
firefox 56.0.2
[34m[1mMongoDB version[0m
MongoDB 3.4.10
[34m[1mPhantomJS version[0m
2.1.1
[34m[1mPre-installed PostgreSQL versions[0m
9.2.24
9.3.20
9.4.15
9.5.10
9.6.6
[34m[1mRabbitMQ Version[0m
3.6.14
[34m[1mRedis version[0m
redis-server 4.0.6
[34m[1mriak version[0m
2.2.3
[34m[1mPre-installed Go versions[0m
1.7.4
[34m[1mant version[0m
Apache Ant(TM) version 1.9.3 compiled on April 8 2014
[34m[1mmvn version[0m
Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z)
Maven home: /usr/local/maven-3.5.2
Java version: 1.8.0_151, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-8-oracle/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.4.0-101-generic", arch: "amd64", family: "unix"
[34m[1mgradle version[0m

------------------------------------------------------------
Gradle 4.0.1
------------------------------------------------------------

Build time:   2017-07-07 14:02:41 UTC
Revision:     38e5dc0f772daecca1d2681885d3d85414eb6826

Groovy:       2.4.11
Ant:          Apache Ant(TM) version 1.9.6 compiled on June 29 2015
JVM:          1.8.0_151 (Oracle Corporation 25.151-b12)
OS:           Linux 4.4.0-101-generic amd64

[34m[1mlein version[0m
Leiningen 2.8.1 on Java 1.8.0_151 Java HotSpot(TM) 64-Bit Server VM
[34m[1mPre-installed Node.js versions[0m
v4.8.6
v6.12.0
v6.12.1
v8.9
v8.9.1
[34m[1mphpenv versions[0m
  system
  5.6
* 5.6.32 (set by /home/travis/.phpenv/version)
  7.0
  7.0.25
  7.1
  7.1.11
  hhvm
  hhvm-stable
[34m[1mcomposer --version[0m
Composer version 1.5.2 2017-09-11 16:59:25
[34m[1mPre-installed Ruby versions[0m
ruby-2.2.7
ruby-2.3.4
ruby-2.4.1
travis_fold:end:system_info[0K
W: The repository 'http://www.apache.org/dist/cassandra/debian 39x Release' does not have a Release file.
W: GPG error: http://dl.google.com/linux/chrome/deb stable InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 78BD65473CB3BD13
W: The repository 'http://dl.google.com/linux/chrome/deb stable InRelease' is not signed.
W: There is no public key available for the following key IDs:
78BD65473CB3BD13  
W: GPG error: http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 Release: The following signatures were invalid: KEYEXPIRED 1515625755
W: The repository 'http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 Release' is not signed.
W: The repository 'http://apt.postgresql.org/pub/repos/apt trusty-pgdg Release' does not have a Release file.
W: The repository 'https://packagecloud.io/basho/riak/ubuntu trusty Release' does not have a Release file.
W: GPG error: https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 6B05F25D762E3157
W: The repository 'https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease' is not signed.
W: There is no public key available for the following key IDs:
6B05F25D762E3157  
W: GPG error: https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY F6609E60DC62814E
W: The repository 'https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu trusty InRelease' is not signed.
W: There is no public key available for the following key IDs:
F6609E60DC62814E  
W: http://ppa.launchpad.net/couchdb/stable/ubuntu/dists/trusty/Release.gpg: Signature by key 15866BAFD9BCC4F3C1E0DFC7D69548E1C17EAB57 uses weak digest algorithm (SHA1)
E: Failed to fetch https://www.apache.org/dist/cassandra/debian/dists/39x/main/binary-amd64/Packages  gnutls_handshake() failed: Handshake failed
E: Failed to fetch https://www.apache.org/dist/cassandra/debian/dists/39x/main/binary-i386/Packages  gnutls_handshake() failed: Handshake failed
E: Failed to fetch http://apt.postgresql.org/pub/repos/apt/dists/trusty-pgdg/main/binary-amd64/Packages  404  Not Found [IP: 147.75.85.69 80]
E: Failed to fetch http://apt.postgresql.org/pub/repos/apt/dists/trusty-pgdg/main/binary-i386/Packages  404  Not Found [IP: 147.75.85.69 80]
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/source/Sources  HttpError402
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/binary-amd64/Packages  HttpError402
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/binary-i386/Packages  HttpError402
E: Some index files failed to download. They have been ignored, or old ones used instead.
sed: cannot rename /etc/hosts: Device or resource busy
sed: cannot rename /etc/hosts: Device or resource busy
$ jdk_switcher use oraclejdk8
Switching to Oracle JDK8 (java-8-oracle), JAVA_HOME will be set to /usr/lib/jvm/java-8-oracle
$ cd passed/crate/crate-jdbc
travis_fold:start:git.submodule[0Ktravis_time:start:20aecc28[0K$ git submodule update --init --recursive

travis_time:end:20aecc28:start=1642675599244161505,finish=1642675599568448451,duration=324286946[0Ktravis_fold:end:git.submodule[0K
[33;1mSetting environment variables from .travis.yml[0m
$ export CRATE_VERSION=0.56.4

$ export TERM=dumb
travis_fold:start:cache.1[0KSetting up build cache
$ export CASHER_DIR=$HOME/.casher
travis_time:start:07517d5a[0K
travis_time:end:07517d5a:start=1642675600556506254,finish=1642675600564955841,duration=8449587[0Ktravis_time:start:1868ee60[0K/home/travis/.casher/bin/casher:213:in `cache_archive_name': undefined method `[]' for nil:NilClass (NoMethodError)
	from /home/travis/.casher/bin/casher:65:in `block in fetch'
	from /home/travis/.casher/bin/casher:64:in `each'
	from /home/travis/.casher/bin/casher:64:in `fetch'
	from /home/travis/.casher/bin/casher:53:in `block in run'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:88:in `block in timeout'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `block in catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:103:in `timeout'
	from /home/travis/.casher/bin/casher:53:in `run'
	from /home/travis/.casher/bin/casher:263:in `<main>'
[32;1mattempting to download cache archive[0m

travis_time:end:1868ee60:start=1642675600577592763,finish=1642675601489739307,duration=912146544[0Ktravis_time:start:135a7c58[0K
travis_time:end:135a7c58:start=1642675601501922431,finish=1642675601511980018,duration=10057587[0Ktravis_time:start:046849db[0K[32;1madding /home/travis/.m2 to cache[0m

travis_time:end:046849db:start=1642675601522613536,finish=1642675602405003102,duration=882389566[0Ktravis_fold:end:cache.1[0K$ java -Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
java version "1.8.0_151"
Java(TM) SE Runtime Environment (build 1.8.0_151-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode)
$ javac -J-Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
javac 1.8.0_151
travis_fold:start:install[0Ktravis_time:start:39fbded7[0K$ JAVA_HOME=$(jdk_switcher home openjdk8) ./gradlew classes testClasses
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Starting a Gradle Daemon, 2 incompatible and 1 stopped Daemons could not be reused, use --status for details
:pg:preprocessJava
Preproces: upstream/pgjdbc/src/main/java -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/java
Preproces: upstream/pgjdbc/src/main/resources -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/resources
:pg:compileJava UP-TO-DATE
:pg:processResources UP-TO-DATE
:pg:classes UP-TO-DATE
:pg:jar UP-TO-DATE
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:compileTestJava UP-TO-DATE
:processTestResources NO-SOURCE
:testClasses UP-TO-DATE
:pg:compileTestJava NO-SOURCE
:pg:processTestResources NO-SOURCE
:pg:testClasses UP-TO-DATE

BUILD SUCCESSFUL in 25s
7 actionable tasks: 1 executed, 6 up-to-date

travis_time:end:39fbded7:start=1642675602677082581,finish=1642675628453350811,duration=25776268230[0Ktravis_fold:end:install[0Ktravis_time:start:0afb21f0[0K$ ./gradlew test -s
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Starting a Gradle Daemon, 2 incompatible and 2 stopped Daemons could not be reused, use --status for details
:pg:preprocessJava
Preproces: upstream/pgjdbc/src/main/java -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/java
Preproces: upstream/pgjdbc/src/main/resources -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/resources
:pg:compileJava UP-TO-DATE
:pg:processResources UP-TO-DATE
:pg:classes UP-TO-DATE
:pg:jar UP-TO-DATE
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:compileTestJava UP-TO-DATE
:processTestResources NO-SOURCE
:testClasses UP-TO-DATE
:testPicked up _JAVA_OPTIONS: -Xmx2048m -Xms512m


io.crate.client.jdbc.integrationtests.CrateJDBCByPassSpecSettingTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-20 10:47:20,259][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-20 10:47:20,402][INFO ][node                     ] [Grabspitze] version[2.3.4], pid[2785], build[${build/NA]
[2022-01-20 10:47:20,402][INFO ][node                     ] [Grabspitze] initializing ...
[2022-01-20 10:47:20,653][INFO ][io.crate.plugin          ] [Grabspitze] plugins loaded: [crate-sigar] 
[2022-01-20 10:47:21,493][INFO ][plugins                  ] [Grabspitze] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-20 10:47:21,513][INFO ][env                      ] [Grabspitze] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.6tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-20 10:47:21,513][INFO ][env                      ] [Grabspitze] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-20 10:47:21,513][WARN ][env                      ] [Grabspitze] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-20 10:47:21,680][INFO ][http                     ] [Grabspitze] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-20 10:47:21,688][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_10dfb153-b8d9-4cd8-acdd-312c8acfab52/plugins/elasticsearch-repository-hdfs/
[2022-01-20 10:47:21,732][INFO ][io.crate.module          ] [Grabspitze] configuring crate. version: 0.56.4
[2022-01-20 10:47:21,897][INFO ][io.crate.module          ] [Grabspitze] configuring crate. version: 0.56.4
[2022-01-20 10:47:22,972][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5483]
[2022-01-20 10:47:22,973][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-20 10:47:24,113][INFO ][io.crate.rest            ] [Grabspitze] Elasticsearch HTTP REST API not enabled
[2022-01-20 10:47:24,167][INFO ][node                     ] [Grabspitze] initialized
[2022-01-20 10:47:24,167][INFO ][node                     ] [Grabspitze] starting ...
[2022-01-20 10:47:24,304][INFO ][io.crate.blob.BlobService] [Grabspitze] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-20 10:47:24,446][INFO ][http                     ] [Grabspitze] publish_address {127.0.0.1:4546}, bound_addresses {127.0.0.1:4546}
[2022-01-20 10:47:24,617][INFO ][transport                ] [Grabspitze] publish_address {127.0.0.1:4374}, bound_addresses {127.0.0.1:4374}
[2022-01-20 10:47:24,626][INFO ][discovery                ] [Grabspitze] TestingCluster/r5Pryy8KQgCg5S_6JBrQzQ
    Stopping crate server process...
[2022-01-20 10:47:26,959][INFO ][node                     ] [Grabspitze] stopping ...
[2022-01-20 10:47:27,006][INFO ][node                     ] [Grabspitze] stopped
[2022-01-20 10:47:27,007][INFO ][node                     ] [Grabspitze] closing ...
[2022-01-20 10:47:27,013][INFO ][node                     ] [Grabspitze] closed

io.crate.client.jdbc.integrationtests.CrateJDBCConnectionTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-20 10:47:28,368][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-20 10:47:28,484][INFO ][node                     ] [Pic Grillon] version[2.3.4], pid[3144], build[${build/NA]
[2022-01-20 10:47:28,484][INFO ][node                     ] [Pic Grillon] initializing ...
[2022-01-20 10:47:28,696][INFO ][io.crate.plugin          ] [Pic Grillon] plugins loaded: [crate-sigar] 
[2022-01-20 10:47:29,487][INFO ][plugins                  ] [Pic Grillon] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-20 10:47:29,508][INFO ][env                      ] [Pic Grillon] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.6tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-20 10:47:29,508][INFO ][env                      ] [Pic Grillon] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-20 10:47:29,508][WARN ][env                      ] [Pic Grillon] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-20 10:47:29,704][INFO ][http                     ] [Pic Grillon] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-20 10:47:29,716][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_39a89e9b-97ab-4332-8f86-757d4bb924fa/plugins/elasticsearch-repository-hdfs/
[2022-01-20 10:47:29,760][INFO ][io.crate.module          ] [Pic Grillon] configuring crate. version: 0.56.4
[2022-01-20 10:47:29,901][INFO ][io.crate.module          ] [Pic Grillon] configuring crate. version: 0.56.4
[2022-01-20 10:47:31,051][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5466]
[2022-01-20 10:47:31,051][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-20 10:47:32,190][INFO ][io.crate.rest            ] [Pic Grillon] Elasticsearch HTTP REST API not enabled
[2022-01-20 10:47:32,233][INFO ][node                     ] [Pic Grillon] initialized
[2022-01-20 10:47:32,233][INFO ][node                     ] [Pic Grillon] starting ...
[2022-01-20 10:47:32,366][INFO ][io.crate.blob.BlobService] [Pic Grillon] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-20 10:47:32,474][INFO ][http                     ] [Pic Grillon] publish_address {127.0.0.1:4524}, bound_addresses {127.0.0.1:4524}
[2022-01-20 10:47:32,568][INFO ][transport                ] [Pic Grillon] publish_address {127.0.0.1:4346}, bound_addresses {127.0.0.1:4346}
[2022-01-20 10:47:32,575][INFO ][discovery                ] [Pic Grillon] TestingCluster/Cd0ZlLH4SJO_wCo5NZlwBw
[2022-01-20 10:47:33,607][DEBUG][action.admin.indices.create] [Pic Grillon] no known master node, scheduling a retry
[2022-01-20 10:47:35,605][INFO ][cluster.service          ] [Pic Grillon] new_master {Pic Grillon}{Cd0ZlLH4SJO_wCo5NZlwBw}{127.0.0.1}{127.0.0.1:4346}{info.extended.type=sigar, http_address=127.0.0.1:4524}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-01-20 10:47:35,609][INFO ][node                     ] [Pic Grillon] started
[2022-01-20 10:47:36,315][INFO ][gateway                  ] [Pic Grillon] recovered [0] indices into cluster_state
[2022-01-20 10:47:36,517][INFO ][cluster.metadata         ] [Pic Grillon] [test] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-01-20 10:47:37,889][INFO ][cluster.routing.allocation] [Pic Grillon] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test][0]] ...]).
[2022-01-20 10:47:39,199][DEBUG][action.bulk              ] create new coordinator for node Cd0ZlLH4SJO_wCo5NZlwBw and shard [test][0]
    Stopping crate server process...
[2022-01-20 10:47:41,665][INFO ][node                     ] [Pic Grillon] stopping ...
[2022-01-20 10:47:43,618][INFO ][node                     ] [Pic Grillon] stopped
[2022-01-20 10:47:43,619][INFO ][node                     ] [Pic Grillon] closing ...
[2022-01-20 10:47:43,628][INFO ][node                     ] [Pic Grillon] closed

io.crate.client.jdbc.integrationtests.CrateJDBCDriverTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-20 10:47:44,668][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-20 10:47:44,793][INFO ][node                     ] [Oberalpstock] version[2.3.4], pid[3535], build[${build/NA]
[2022-01-20 10:47:44,793][INFO ][node                     ] [Oberalpstock] initializing ...
[2022-01-20 10:47:45,043][INFO ][io.crate.plugin          ] [Oberalpstock] plugins loaded: [crate-sigar] 
[2022-01-20 10:47:45,785][INFO ][plugins                  ] [Oberalpstock] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-20 10:47:45,802][INFO ][env                      ] [Oberalpstock] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.6tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-20 10:47:45,802][INFO ][env                      ] [Oberalpstock] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-20 10:47:45,802][WARN ][env                      ] [Oberalpstock] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-20 10:47:46,000][INFO ][http                     ] [Oberalpstock] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-20 10:47:46,010][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_2958b1a2-8576-40a9-8689-352207176a4f/plugins/elasticsearch-repository-hdfs/
[2022-01-20 10:47:46,066][INFO ][io.crate.module          ] [Oberalpstock] configuring crate. version: 0.56.4
[2022-01-20 10:47:46,235][INFO ][io.crate.module          ] [Oberalpstock] configuring crate. version: 0.56.4
[2022-01-20 10:47:47,215][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5452]
[2022-01-20 10:47:47,216][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-20 10:47:48,292][INFO ][io.crate.rest            ] [Oberalpstock] Elasticsearch HTTP REST API not enabled
[2022-01-20 10:47:48,336][INFO ][node                     ] [Oberalpstock] initialized
[2022-01-20 10:47:48,336][INFO ][node                     ] [Oberalpstock] starting ...
[2022-01-20 10:47:48,478][INFO ][io.crate.blob.BlobService] [Oberalpstock] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-20 10:47:48,580][INFO ][http                     ] [Oberalpstock] publish_address {127.0.0.1:4554}, bound_addresses {127.0.0.1:4554}
[2022-01-20 10:47:48,662][INFO ][transport                ] [Oberalpstock] publish_address {127.0.0.1:4311}, bound_addresses {127.0.0.1:4311}
[2022-01-20 10:47:48,667][INFO ][discovery                ] [Oberalpstock] TestingCluster/VSzzPTe2Sx28ARlt9WaSKQ
    Stopping crate server process...
[2022-01-20 10:47:48,941][INFO ][node                     ] [Oberalpstock] stopping ...
[2022-01-20 10:47:49,005][INFO ][node                     ] [Oberalpstock] stopped
[2022-01-20 10:47:49,005][INFO ][node                     ] [Oberalpstock] closing ...
[2022-01-20 10:47:49,010][INFO ][node                     ] [Oberalpstock] closed

io.crate.client.jdbc.integrationtests.CrateJDBCFetchSizeIntegrationTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-20 10:47:50,203][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-20 10:47:50,355][INFO ][node                     ] [Hohe Wei√üe] version[2.3.4], pid[3892], build[${build/NA]
[2022-01-20 10:47:50,356][INFO ][node                     ] [Hohe Wei√üe] initializing ...
[2022-01-20 10:47:50,600][INFO ][io.crate.plugin          ] [Hohe Wei√üe] plugins loaded: [crate-sigar] 
[2022-01-20 10:47:51,449][INFO ][plugins                  ] [Hohe Wei√üe] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-20 10:47:51,470][INFO ][env                      ] [Hohe Wei√üe] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.6tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-20 10:47:51,470][INFO ][env                      ] [Hohe Wei√üe] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-20 10:47:51,470][WARN ][env                      ] [Hohe Wei√üe] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-20 10:47:51,658][INFO ][http                     ] [Hohe Wei√üe] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-20 10:47:51,669][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_22bcac14-1dac-4825-a026-5585ddf3d739/plugins/elasticsearch-repository-hdfs/
[2022-01-20 10:47:51,724][INFO ][io.crate.module          ] [Hohe Wei√üe] configuring crate. version: 0.56.4
[2022-01-20 10:47:51,881][INFO ][io.crate.module          ] [Hohe Wei√üe] configuring crate. version: 0.56.4
[2022-01-20 10:47:52,932][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5523]
[2022-01-20 10:47:52,932][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-20 10:47:54,040][INFO ][io.crate.rest            ] [Hohe Wei√üe] Elasticsearch HTTP REST API not enabled
[2022-01-20 10:47:54,085][INFO ][node                     ] [Hohe Wei√üe] initialized
[2022-01-20 10:47:54,085][INFO ][node                     ] [Hohe Wei√üe] starting ...
[2022-01-20 10:47:54,239][INFO ][io.crate.blob.BlobService] [Hohe Wei√üe] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-20 10:47:54,342][INFO ][http                     ] [Hohe Wei√üe] publish_address {127.0.0.1:4510}, bound_addresses {127.0.0.1:4510}
[2022-01-20 10:47:54,414][INFO ][transport                ] [Hohe Wei√üe] publish_address {127.0.0.1:4356}, bound_addresses {127.0.0.1:4356}
[2022-01-20 10:47:54,419][INFO ][discovery                ] [Hohe Wei√üe] TestingCluster/2HaH_8LPS3OyUTuCkCdxvg
    Stopping crate server process...
[2022-01-20 10:47:55,465][INFO ][node                     ] [Hohe Wei√üe] stopping ...
[2022-01-20 10:47:55,936][WARN ][discovery.zen.ping.unicast] [Hohe Wei√üe] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:4356}]
SendRequestTransportException[[Hohe Wei√üe][127.0.0.1:4356][internal:discovery/zen/unicast]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:336)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:316)
	... 7 more
[2022-01-20 10:47:55,936][WARN ][discovery.zen.ping.unicast] [Hohe Wei√üe] failed to send ping to [{Hohe Wei√üe}{2HaH_8LPS3OyUTuCkCdxvg}{127.0.0.1}{127.0.0.1:4356}{info.extended.type=sigar, http_address=127.0.0.1:4510}]
SendRequestTransportException[[Hohe Wei√üe][127.0.0.1:4356][internal:discovery/zen/unicast]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:336)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:316)
	... 7 more
[2022-01-20 10:47:57,003][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:577)
	at org.jboss.netty.channel.Channels.write(Channels.java:704)
	at org.jboss.netty.channel.Channels.write(Channels.java:671)
	at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:348)
	at io.crate.protocols.postgres.Messages.sendErrorResponse(Messages.java:231)
	at io.crate.protocols.postgres.ResultSetReceiver.fail(ResultSetReceiver.java:79)
	at io.crate.protocols.postgres.SimplePortal$ResultReceiverRetryWrapper.fail(SimplePortal.java:273)
	at io.crate.action.sql.RowReceiverToResultReceiver.fail(RowReceiverToResultReceiver.java:67)
	at io.crate.executor.transport.executionphases.InterceptingRowReceiver$1.onFailure(InterceptingRowReceiver.java:133)
	at io.crate.executor.MultiActionListener.countdown(MultiActionListener.java:68)
	at io.crate.executor.MultiActionListener.onFailure(MultiActionListener.java:59)
	at io.crate.executor.transport.DefaultTransportResponseHandler.handleException(DefaultTransportResponseHandler.java:62)
	at org.elasticsearch.transport.TransportService$3.doRun(TransportService.java:349)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-01-20 10:47:57,004][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:577)
	at org.jboss.netty.channel.Channels.write(Channels.java:704)
	at org.jboss.netty.channel.Channels.write(Channels.java:671)
	at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:348)
	at io.crate.protocols.postgres.Messages.sendReadyForQuery(Messages.java:140)
	at io.crate.protocols.postgres.ConnectionContext$ReadyForQueryListener.onFailure(ConnectionContext.java:222)
	at io.crate.concurrent.CompletionMultiListener.onFailure(CompletionMultiListener.java:63)
	at io.crate.protocols.postgres.ResultSetReceiver.fail(ResultSetReceiver.java:80)
	at io.crate.protocols.postgres.SimplePortal$ResultReceiverRetryWrapper.fail(SimplePortal.java:273)
	at io.crate.action.sql.RowReceiverToResultReceiver.fail(RowReceiverToResultReceiver.java:67)
	at io.crate.executor.transport.executionphases.InterceptingRowReceiver$1.onFailure(InterceptingRowReceiver.java:133)
	at io.crate.executor.MultiActionListener.countdown(MultiActionListener.java:68)
	at io.crate.executor.MultiActionListener.onFailure(MultiActionListener.java:59)
	at io.crate.executor.transport.DefaultTransportResponseHandler.handleException(DefaultTransportResponseHandler.java:62)
	at org.elasticsearch.transport.TransportService$3.doRun(TransportService.java:349)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-01-20 10:47:57,004][INFO ][node                     ] [Hohe Wei√üe] stopped
[2022-01-20 10:47:57,005][INFO ][node                     ] [Hohe Wei√üe] closing ...
[2022-01-20 10:47:57,012][INFO ][node                     ] [Hohe Wei√üe] closed

io.crate.client.jdbc.integrationtests.CrateJDBCMetaDataIntegrationTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-20 10:47:58,460][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-20 10:47:58,587][INFO ][node                     ] [Kanisfluh] version[2.3.4], pid[4253], build[${build/NA]
[2022-01-20 10:47:58,588][INFO ][node                     ] [Kanisfluh] initializing ...
[2022-01-20 10:47:58,857][INFO ][io.crate.plugin          ] [Kanisfluh] plugins loaded: [crate-sigar] 
[2022-01-20 10:47:59,693][INFO ][plugins                  ] [Kanisfluh] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-20 10:47:59,713][INFO ][env                      ] [Kanisfluh] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.6tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-20 10:47:59,714][INFO ][env                      ] [Kanisfluh] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-20 10:47:59,714][WARN ][env                      ] [Kanisfluh] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-20 10:47:59,919][INFO ][http                     ] [Kanisfluh] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-20 10:47:59,929][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_acf2ccd8-5606-4c43-afa0-a51980fc4874/plugins/elasticsearch-repository-hdfs/
[2022-01-20 10:47:59,982][INFO ][io.crate.module          ] [Kanisfluh] configuring crate. version: 0.56.4
[2022-01-20 10:48:00,150][INFO ][io.crate.module          ] [Kanisfluh] configuring crate. version: 0.56.4
[2022-01-20 10:48:01,275][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5436]
[2022-01-20 10:48:01,275][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-20 10:48:02,436][INFO ][io.crate.rest            ] [Kanisfluh] Elasticsearch HTTP REST API not enabled
[2022-01-20 10:48:02,485][INFO ][node                     ] [Kanisfluh] initialized
[2022-01-20 10:48:02,485][INFO ][node                     ] [Kanisfluh] starting ...
[2022-01-20 10:48:02,669][INFO ][io.crate.blob.BlobService] [Kanisfluh] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-20 10:48:02,768][INFO ][http                     ] [Kanisfluh] publish_address {127.0.0.1:4547}, bound_addresses {127.0.0.1:4547}
[2022-01-20 10:48:02,874][INFO ][transport                ] [Kanisfluh] publish_address {127.0.0.1:4388}, bound_addresses {127.0.0.1:4388}
[2022-01-20 10:48:02,881][INFO ][discovery                ] [Kanisfluh] TestingCluster/QjqtEAx5RRqS2SYXTRKmBQ
[2022-01-20 10:48:03,686][DEBUG][action.admin.indices.create] [Kanisfluh] no known master node, scheduling a retry
[2022-01-20 10:48:05,914][INFO ][cluster.service          ] [Kanisfluh] new_master {Kanisfluh}{QjqtEAx5RRqS2SYXTRKmBQ}{127.0.0.1}{127.0.0.1:4388}{info.extended.type=sigar, http_address=127.0.0.1:4547}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-01-20 10:48:05,920][INFO ][node                     ] [Kanisfluh] started
[2022-01-20 10:48:06,587][INFO ][gateway                  ] [Kanisfluh] recovered [0] indices into cluster_state
[2022-01-20 10:48:06,742][INFO ][cluster.metadata         ] [Kanisfluh] [test.cluster] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-20 10:48:08,051][INFO ][cluster.routing.allocation] [Kanisfluh] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[test.cluster][3], [test.cluster][2], [test.cluster][1], [test.cluster][0]] ...]).
[2022-01-20 10:48:08,074][INFO ][cluster.metadata         ] [Kanisfluh] [names] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-20 10:48:10,661][INFO ][cluster.routing.allocation] [Kanisfluh] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[names][3], [names][0], [names][2], [names][1]] ...]).
[2022-01-20 10:48:11,176][INFO ][cluster.metadata         ] [Kanisfluh] [my_schema.names] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-20 10:48:12,891][INFO ][cluster.routing.allocation] [Kanisfluh] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[my_schema.names][1], [my_schema.names][2], [my_schema.names][3], [my_schema.names][0]] ...]).
[2022-01-20 10:48:17,216][INFO ][cluster.metadata         ] [Kanisfluh] [t_multi_pks] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-20 10:48:20,447][INFO ][cluster.routing.allocation] [Kanisfluh] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[t_multi_pks][2], [t_multi_pks][1], [t_multi_pks][3], [t_multi_pks][0]] ...]).
    Stopping crate server process...
[2022-01-20 10:48:24,358][INFO ][node                     ] [Kanisfluh] stopping ...
[2022-01-20 10:48:24,522][INFO ][node                     ] [Kanisfluh] stopped
[2022-01-20 10:48:24,523][INFO ][node                     ] [Kanisfluh] closing ...
[2022-01-20 10:48:24,544][INFO ][node                     ] [Kanisfluh] closed

io.crate.client.jdbc.integrationtests.CrateJDBCTypesTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-20 10:48:25,792][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-20 10:48:25,919][INFO ][node                     ] [Dent de Barme] version[2.3.4], pid[4656], build[${build/NA]
[2022-01-20 10:48:25,919][INFO ][node                     ] [Dent de Barme] initializing ...
[2022-01-20 10:48:26,212][INFO ][io.crate.plugin          ] [Dent de Barme] plugins loaded: [crate-sigar] 
[2022-01-20 10:48:27,075][INFO ][plugins                  ] [Dent de Barme] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-20 10:48:27,095][INFO ][env                      ] [Dent de Barme] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.6tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-20 10:48:27,095][INFO ][env                      ] [Dent de Barme] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-20 10:48:27,095][WARN ][env                      ] [Dent de Barme] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-20 10:48:27,296][INFO ][http                     ] [Dent de Barme] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-20 10:48:27,304][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_684905b7-ccb7-455d-8ba9-7c74591310cf/plugins/elasticsearch-repository-hdfs/
[2022-01-20 10:48:27,346][INFO ][io.crate.module          ] [Dent de Barme] configuring crate. version: 0.56.4
[2022-01-20 10:48:27,497][INFO ][io.crate.module          ] [Dent de Barme] configuring crate. version: 0.56.4
[2022-01-20 10:48:28,564][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5471]
[2022-01-20 10:48:28,564][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-20 10:48:29,819][INFO ][io.crate.rest            ] [Dent de Barme] Elasticsearch HTTP REST API not enabled
[2022-01-20 10:48:29,870][INFO ][node                     ] [Dent de Barme] initialized
[2022-01-20 10:48:29,870][INFO ][node                     ] [Dent de Barme] starting ...
[2022-01-20 10:48:30,021][INFO ][io.crate.blob.BlobService] [Dent de Barme] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-20 10:48:30,159][INFO ][http                     ] [Dent de Barme] publish_address {127.0.0.1:4507}, bound_addresses {127.0.0.1:4507}
[2022-01-20 10:48:30,274][INFO ][transport                ] [Dent de Barme] publish_address {127.0.0.1:4368}, bound_addresses {127.0.0.1:4368}
[2022-01-20 10:48:30,280][INFO ][discovery                ] [Dent de Barme] TestingCluster/Ci9XUzjNTFeAv2ayZeg4DQ
[2022-01-20 10:48:30,935][DEBUG][action.admin.indices.create] [Dent de Barme] no known master node, scheduling a retry
[2022-01-20 10:48:33,316][INFO ][cluster.service          ] [Dent de Barme] new_master {Dent de Barme}{Ci9XUzjNTFeAv2ayZeg4DQ}{127.0.0.1}{127.0.0.1:4368}{info.extended.type=sigar, http_address=127.0.0.1:4507}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-01-20 10:48:33,323][INFO ][node                     ] [Dent de Barme] started
[2022-01-20 10:48:34,013][INFO ][gateway                  ] [Dent de Barme] recovered [0] indices into cluster_state
[2022-01-20 10:48:34,224][INFO ][cluster.metadata         ] [Dent de Barme] [test] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-01-20 10:48:35,414][INFO ][cluster.routing.allocation] [Dent de Barme] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test][0]] ...]).
[2022-01-20 10:48:36,243][INFO ][cluster.metadata         ] [Dent de Barme] [arraytest] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-01-20 10:48:37,828][INFO ][cluster.routing.allocation] [Dent de Barme] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[arraytest][0]] ...]).
[2022-01-20 10:48:37,989][INFO ][cluster.metadata         ] [Dent de Barme] [arraytest] update_mapping [default]
[2022-01-20 10:48:38,868][INFO ][cluster.metadata         ] [Dent de Barme] [test_obj] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-01-20 10:48:40,582][INFO ][cluster.routing.allocation] [Dent de Barme] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[test_obj][0], [test_obj][3], [test_obj][2], [test_obj][1]] ...]).
    Stopping crate server process...
[2022-01-20 10:48:43,198][INFO ][node                     ] [Dent de Barme] stopping ...
[2022-01-20 10:48:44,720][INFO ][node                     ] [Dent de Barme] stopped
[2022-01-20 10:48:44,720][INFO ][node                     ] [Dent de Barme] closing ...
[2022-01-20 10:48:44,732][INFO ][node                     ] [Dent de Barme] closed

io.crate.client.jdbc.integrationtests.CrateJDBCUnsupportedFeaturesTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-01-20 10:48:46,173][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-01-20 10:48:46,300][INFO ][node                     ] [Signal du Lauvitel E] version[2.3.4], pid[5108], build[${build/NA]
[2022-01-20 10:48:46,300][INFO ][node                     ] [Signal du Lauvitel E] initializing ...
[2022-01-20 10:48:46,596][INFO ][io.crate.plugin          ] [Signal du Lauvitel E] plugins loaded: [crate-sigar] 
[2022-01-20 10:48:47,513][INFO ][plugins                  ] [Signal du Lauvitel E] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-01-20 10:48:47,535][INFO ][env                      ] [Signal du Lauvitel E] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.6tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-01-20 10:48:47,536][INFO ][env                      ] [Signal du Lauvitel E] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-01-20 10:48:47,536][WARN ][env                      ] [Signal du Lauvitel E] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-01-20 10:48:47,756][INFO ][http                     ] [Signal du Lauvitel E] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-01-20 10:48:47,767][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_9b2d25a7-bd76-457a-9d36-25b6d233cd73/plugins/elasticsearch-repository-hdfs/
[2022-01-20 10:48:47,817][INFO ][io.crate.module          ] [Signal du Lauvitel E] configuring crate. version: 0.56.4
[2022-01-20 10:48:48,033][INFO ][io.crate.module          ] [Signal du Lauvitel E] configuring crate. version: 0.56.4
[2022-01-20 10:48:49,306][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5520]
[2022-01-20 10:48:49,307][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-01-20 10:48:50,492][INFO ][io.crate.rest            ] [Signal du Lauvitel E] Elasticsearch HTTP REST API not enabled
[2022-01-20 10:48:50,547][INFO ][node                     ] [Signal du Lauvitel E] initialized
[2022-01-20 10:48:50,547][INFO ][node                     ] [Signal du Lauvitel E] starting ...
[2022-01-20 10:48:50,680][INFO ][io.crate.blob.BlobService] [Signal du Lauvitel E] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-01-20 10:48:50,819][INFO ][http                     ] [Signal du Lauvitel E] publish_address {127.0.0.1:4593}, bound_addresses {127.0.0.1:4593}
[2022-01-20 10:48:50,922][INFO ][transport                ] [Signal du Lauvitel E] publish_address {127.0.0.1:4250}, bound_addresses {127.0.0.1:4250}
[2022-01-20 10:48:50,930][INFO ][discovery                ] [Signal du Lauvitel E] TestingCluster/wGfL5yTnTqOAKsGzl7bBTA
    Stopping crate server process...
[2022-01-20 10:48:51,323][INFO ][node                     ] [Signal du Lauvitel E] stopping ...
[2022-01-20 10:48:51,392][INFO ][node                     ] [Signal du Lauvitel E] stopped
[2022-01-20 10:48:51,392][INFO ][node                     ] [Signal du Lauvitel E] closing ...
[2022-01-20 10:48:51,397][INFO ][node                     ] [Signal du Lauvitel E] closed
:pg:compileTestJava NO-SOURCE
:pg:processTestResources NO-SOURCE
:pg:testClasses UP-TO-DATE
:pg:test SKIPPED

BUILD SUCCESSFUL in 1m 43s
8 actionable tasks: 2 executed, 6 up-to-date

travis_time:end:0afb21f0:start=1642675628464366720,finish=1642675732093488719,duration=103629121999[0K
[32;1mThe command "./gradlew test -s" exited with 0.[0m
travis_fold:start:cache.2[0Kstore build cache
travis_time:start:1eb2e86a[0K
travis_time:end:1eb2e86a:start=1642675732104710460,finish=1642675732113066034,duration=8355574[0Ktravis_time:start:133fdfdc[0K/home/travis/.casher/bin/casher:190: warning: Insecure world writable dir /usr/local/clang-5.0.0/bin in PATH, mode 040777
[32;1mchanges detected, packing new archive[0m
/home/travis/.casher/bin/casher:213:in `cache_archive_name': undefined method `[]' for nil:NilClass (NoMethodError)
	from /home/travis/.casher/bin/casher:143:in `push'
	from /home/travis/.casher/bin/casher:53:in `block in run'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:88:in `block in timeout'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `block in catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:103:in `timeout'
	from /home/travis/.casher/bin/casher:53:in `run'
	from /home/travis/.casher/bin/casher:263:in `<main>'

travis_time:end:133fdfdc:start=1642675732124598271,finish=1642675733928212324,duration=1803614053[0Ktravis_fold:end:cache.2[0K
Done. Your build exited with 0.
