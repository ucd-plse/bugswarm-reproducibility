travis_fold:start:system_info[0K[33;1mBuild system information[0m
Build language: java
Build group: stable
Build dist: trusty
Build id: ''
Job id: ''
[34m[1mBuild image provisioning date and time[0m
Tue Dec  5 20:11:19 UTC 2017
[34m[1mOperating System Details[0m
Distributor ID:	Ubuntu
Description:	Ubuntu 14.04.5 LTS
Release:	14.04
Codename:	trusty
[34m[1mCookbooks Version[0m
7c2c6a6 https://github.com/travis-ci/travis-cookbooks/tree/7c2c6a6
[34m[1mgit version[0m
git version 2.15.1
[34m[1mbash version[0m
GNU bash, version 4.3.11(1)-release (x86_64-pc-linux-gnu)
[34m[1mgcc version[0m
gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[34m[1mdocker version[0m
Client:
 Version:      17.09.0-ce
 API version:  1.32
 Go version:   go1.8.3
 Git commit:   afdb6d4
 Built:        Tue Sep 26 22:39:28 2017
 OS/Arch:      linux/amd64
[34m[1mclang version[0m
clang version 5.0.0 (tags/RELEASE_500/final)
Target: x86_64-unknown-linux-gnu
Thread model: posix
InstalledDir: /usr/local/clang-5.0.0/bin
[34m[1mjq version[0m
jq-1.5
[34m[1mbats version[0m
Bats 0.4.0
[34m[1mshellcheck version[0m
0.4.6
[34m[1mshfmt version[0m
v2.0.0
[34m[1mccache version[0m
ccache version 3.1.9

Copyright (C) 2002-2007 Andrew Tridgell
Copyright (C) 2009-2011 Joel Rosdahl

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License as published by the Free Software
Foundation; either version 3 of the License, or (at your option) any later
version.
[34m[1mcmake version[0m
cmake version 3.9.2

CMake suite maintained and supported by Kitware (kitware.com/cmake).
[34m[1mheroku version[0m
heroku-cli/6.14.39-addc925 (linux-x64) node-v9.2.0
[34m[1mimagemagick version[0m
Version: ImageMagick 6.7.7-10 2017-07-31 Q16 http://www.imagemagick.org
[34m[1mmd5deep version[0m
4.2
[34m[1mmercurial version[0m
Mercurial Distributed SCM (version 4.2.2)
(see https://mercurial-scm.org for more information)

Copyright (C) 2005-2017 Matt Mackall and others
This is free software; see the source for copying conditions. There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
[34m[1mmysql version[0m
mysql  Ver 14.14 Distrib 5.6.33, for debian-linux-gnu (x86_64) using  EditLine wrapper
[34m[1mopenssl version[0m
OpenSSL 1.0.1f 6 Jan 2014
[34m[1mpacker version[0m
Packer v1.0.2

Your version of Packer is out of date! The latest version
is 1.1.2. You can update by downloading from www.packer.io
[34m[1mpostgresql client version[0m
psql (PostgreSQL) 9.6.6
[34m[1mragel version[0m
Ragel State Machine Compiler version 6.8 Feb 2013
Copyright (c) 2001-2009 by Adrian Thurston
[34m[1msubversion version[0m
svn, version 1.8.8 (r1568071)
   compiled Aug 10 2017, 17:20:39 on x86_64-pc-linux-gnu

Copyright (C) 2013 The Apache Software Foundation.
This software consists of contributions made by many people;
see the NOTICE file for more information.
Subversion is open source software, see http://subversion.apache.org/

The following repository access (RA) modules are available:

* ra_svn : Module for accessing a repository using the svn network protocol.
  - with Cyrus SASL authentication
  - handles 'svn' scheme
* ra_local : Module for accessing a repository on local disk.
  - handles 'file' scheme
* ra_serf : Module for accessing a repository via WebDAV protocol using serf.
  - using serf 1.3.3
  - handles 'http' scheme
  - handles 'https' scheme

[34m[1msudo version[0m
Sudo version 1.8.9p5
Configure options: --prefix=/usr -v --with-all-insults --with-pam --with-fqdn --with-logging=syslog --with-logfac=authpriv --with-env-editor --with-editor=/usr/bin/editor --with-timeout=15 --with-password-timeout=0 --with-passprompt=[sudo] password for %p:  --without-lecture --with-tty-tickets --disable-root-mailer --enable-admin-flag --with-sendmail=/usr/sbin/sendmail --with-timedir=/var/lib/sudo --mandir=/usr/share/man --libexecdir=/usr/lib/sudo --with-sssd --with-sssd-lib=/usr/lib/x86_64-linux-gnu --with-selinux
Sudoers policy plugin version 1.8.9p5
Sudoers file grammar version 43

Sudoers path: /etc/sudoers
Authentication methods: 'pam'
Syslog facility if syslog is being used for logging: authpriv
Syslog priority to use when user authenticates successfully: notice
Syslog priority to use when user authenticates unsuccessfully: alert
Send mail if the user is not in sudoers
Use a separate timestamp for each user/tty combo
Lecture user the first time they run sudo
Root may run sudo
Allow some information gathering to give useful error messages
Require fully-qualified hostnames in the sudoers file
Visudo will honor the EDITOR environment variable
Set the LOGNAME and USER environment variables
Length at which to wrap log file lines (0 for no wrap): 80
Authentication timestamp timeout: 15.0 minutes
Password prompt timeout: 0.0 minutes
Number of tries to enter a password: 3
Umask to use or 0777 to use user's: 022
Path to mail program: /usr/sbin/sendmail
Flags for mail program: -t
Address to send mail to: root
Subject line for mail messages: *** SECURITY information for %h ***
Incorrect password message: Sorry, try again.
Path to authentication timestamp dir: /var/lib/sudo
Default password prompt: [sudo] password for %p: 
Default user to run commands as: root
Value to override user's $PATH with: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin
Path to the editor for use by visudo: /usr/bin/editor
When to require a password for 'list' pseudocommand: any
When to require a password for 'verify' pseudocommand: all
File descriptors >= 3 will be closed before executing a command
Environment variables to check for sanity:
	TZ
	TERM
	LINGUAS
	LC_*
	LANGUAGE
	LANG
	COLORTERM
Environment variables to remove:
	RUBYOPT
	RUBYLIB
	PYTHONUSERBASE
	PYTHONINSPECT
	PYTHONPATH
	PYTHONHOME
	TMPPREFIX
	ZDOTDIR
	READNULLCMD
	NULLCMD
	FPATH
	PERL5DB
	PERL5OPT
	PERL5LIB
	PERLLIB
	PERLIO_DEBUG 
	JAVA_TOOL_OPTIONS
	SHELLOPTS
	GLOBIGNORE
	PS4
	BASH_ENV
	ENV
	TERMCAP
	TERMPATH
	TERMINFO_DIRS
	TERMINFO
	_RLD*
	LD_*
	PATH_LOCALE
	NLSPATH
	HOSTALIASES
	RES_OPTIONS
	LOCALDOMAIN
	CDPATH
	IFS
Environment variables to preserve:
	JAVA_HOME
	TRAVIS
	CI
	DEBIAN_FRONTEND
	XAUTHORIZATION
	XAUTHORITY
	PS2
	PS1
	PATH
	LS_COLORS
	KRB5CCNAME
	HOSTNAME
	HOME
	DISPLAY
	COLORS
Locale to use while parsing sudoers: C
Directory in which to store input/output logs: /var/log/sudo-io
File in which to store the input/output log: %{seq}
Add an entry to the utmp/utmpx file when allocating a pty
PAM service name to use
PAM service name to use for login shells
Create a new PAM session for the command to run in
Maximum I/O log sequence number: 0

Local IP address and netmask pairs:
	172.17.0.2/255.255.0.0

Sudoers I/O plugin version 1.8.9p5
[34m[1mgzip version[0m
gzip 1.6
Copyright (C) 2007, 2010, 2011 Free Software Foundation, Inc.
Copyright (C) 1993 Jean-loup Gailly.
This is free software.  You may redistribute copies of it under the terms of
the GNU General Public License <http://www.gnu.org/licenses/gpl.html>.
There is NO WARRANTY, to the extent permitted by law.

Written by Jean-loup Gailly.
[34m[1mzip version[0m
Copyright (c) 1990-2008 Info-ZIP - Type 'zip "-L"' for software license.
This is Zip 3.0 (July 5th 2008), by Info-ZIP.
Currently maintained by E. Gordon.  Please send bug reports to
the authors using the web page at www.info-zip.org; see README for details.

Latest sources and executables are at ftp://ftp.info-zip.org/pub/infozip,
as of above date; see http://www.info-zip.org/ for other sites.

Compiled with gcc 4.8.2 for Unix (Linux ELF) on Oct 21 2013.

Zip special compilation options:
	USE_EF_UT_TIME       (store Universal Time)
	BZIP2_SUPPORT        (bzip2 library version 1.0.6, 6-Sept-2010)
	    bzip2 code and library copyright (c) Julian R Seward
	    (See the bzip2 license for terms of use)
	SYMLINK_SUPPORT      (symbolic links supported)
	LARGE_FILE_SUPPORT   (can read and write large files on file system)
	ZIP64_SUPPORT        (use Zip64 to store large files in archives)
	UNICODE_SUPPORT      (store and read UTF-8 Unicode paths)
	STORE_UNIX_UIDs_GIDs (store UID/GID sizes/values using new extra field)
	UIDGID_NOT_16BIT     (old Unix 16-bit UID/GID extra field not used)
	[encryption, version 2.91 of 05 Jan 2007] (modified for Zip 3)

Encryption notice:
	The encryption code of this program is not copyrighted and is
	put in the public domain.  It was originally written in Europe
	and, to the best of our knowledge, can be freely distributed
	in both source and object forms from any country, including
	the USA under License Exception TSU of the U.S. Export
	Administration Regulations (section 740.13(e)) of 6 June 2002.

Zip environment options:
             ZIP:  [none]
          ZIPOPT:  [none]
[34m[1mvim version[0m
VIM - Vi IMproved 7.4 (2013 Aug 10, compiled Nov 24 2016 16:43:18)
Included patches: 1-52
Extra patches: 8.0.0056
Modified by pkg-vim-maintainers@lists.alioth.debian.org
Compiled by buildd@
Huge version without GUI.  Features included (+) or not (-):
+acl             +farsi           +mouse_netterm   +syntax
+arabic          +file_in_path    +mouse_sgr       +tag_binary
+autocmd         +find_in_path    -mouse_sysmouse  +tag_old_static
-balloon_eval    +float           +mouse_urxvt     -tag_any_white
-browse          +folding         +mouse_xterm     -tcl
++builtin_terms  -footer          +multi_byte      +terminfo
+byte_offset     +fork()          +multi_lang      +termresponse
+cindent         +gettext         -mzscheme        +textobjects
-clientserver    -hangul_input    +netbeans_intg   +title
-clipboard       +iconv           +path_extra      -toolbar
+cmdline_compl   +insert_expand   -perl            +user_commands
+cmdline_hist    +jumplist        +persistent_undo +vertsplit
+cmdline_info    +keymap          +postscript      +virtualedit
+comments        +langmap         +printer         +visual
+conceal         +libcall         +profile         +visualextra
+cryptv          +linebreak       +python          +viminfo
+cscope          +lispindent      -python3         +vreplace
+cursorbind      +listcmds        +quickfix        +wildignore
+cursorshape     +localmap        +reltime         +wildmenu
+dialog_con      -lua             +rightleft       +windows
+diff            +menu            -ruby            +writebackup
+digraphs        +mksession       +scrollbind      -X11
-dnd             +modify_fname    +signs           -xfontset
-ebcdic          +mouse           +smartindent     -xim
+emacs_tags      -mouseshape      -sniff           -xsmp
+eval            +mouse_dec       +startuptime     -xterm_clipboard
+ex_extra        +mouse_gpm       +statusline      -xterm_save
+extra_search    -mouse_jsbterm   -sun_workshop    -xpm
   system vimrc file: "$VIM/vimrc"
     user vimrc file: "$HOME/.vimrc"
 2nd user vimrc file: "~/.vim/vimrc"
      user exrc file: "$HOME/.exrc"
  fall-back for $VIM: "/usr/share/vim"
Compilation: gcc -c -I. -Iproto -DHAVE_CONFIG_H     -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1      
Linking: gcc   -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,--as-needed -o vim        -lm -ltinfo -lnsl  -lselinux  -lacl -lattr -lgpm -ldl    -L/usr/lib/python2.7/config-x86_64-linux-gnu -lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic -Wl,-O1 -Wl,-Bsymbolic-functions      
[34m[1miptables version[0m
iptables v1.4.21
[34m[1mcurl version[0m
curl 7.35.0 (x86_64-pc-linux-gnu) libcurl/7.35.0 OpenSSL/1.0.1f zlib/1.2.8 libidn/1.28 librtmp/2.3
[34m[1mwget version[0m
GNU Wget 1.15 built on linux-gnu.
[34m[1mrsync version[0m
rsync  version 3.1.0  protocol version 31
[34m[1mgimme version[0m
v1.2.0
[34m[1mnvm version[0m
0.33.6
[34m[1mperlbrew version[0m
/home/travis/perl5/perlbrew/bin/perlbrew  - App::perlbrew/0.80
[34m[1mphpenv version[0m
rbenv 1.1.1-25-g6aa70b6
[34m[1mrvm version[0m
rvm 1.29.3 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io]
[34m[1mdefault ruby version[0m
ruby 2.4.1p111 (2017-03-22 revision 58053) [x86_64-linux]
[34m[1mCouchDB version[0m
couchdb 1.6.1
[34m[1mElasticSearch version[0m
5.5.0
[34m[1mInstalled Firefox version[0m
firefox 56.0.2
[34m[1mMongoDB version[0m
MongoDB 3.4.10
[34m[1mPhantomJS version[0m
2.1.1
[34m[1mPre-installed PostgreSQL versions[0m
9.2.24
9.3.20
9.4.15
9.5.10
9.6.6
[34m[1mRabbitMQ Version[0m
3.6.14
[34m[1mRedis version[0m
redis-server 4.0.6
[34m[1mriak version[0m
2.2.3
[34m[1mPre-installed Go versions[0m
1.7.4
[34m[1mant version[0m
Apache Ant(TM) version 1.9.3 compiled on April 8 2014
[34m[1mmvn version[0m
Apache Maven 3.5.2 (138edd61fd100ec658bfa2d307c43b76940a5d7d; 2017-10-18T07:58:13Z)
Maven home: /usr/local/maven-3.5.2
Java version: 1.8.0_151, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-8-oracle/jre
Default locale: en_US, platform encoding: UTF-8
OS name: "linux", version: "4.4.0-101-generic", arch: "amd64", family: "unix"
[34m[1mgradle version[0m

------------------------------------------------------------
Gradle 4.0.1
------------------------------------------------------------

Build time:   2017-07-07 14:02:41 UTC
Revision:     38e5dc0f772daecca1d2681885d3d85414eb6826

Groovy:       2.4.11
Ant:          Apache Ant(TM) version 1.9.6 compiled on June 29 2015
JVM:          1.8.0_151 (Oracle Corporation 25.151-b12)
OS:           Linux 4.4.0-101-generic amd64

[34m[1mlein version[0m
Leiningen 2.8.1 on Java 1.8.0_151 Java HotSpot(TM) 64-Bit Server VM
[34m[1mPre-installed Node.js versions[0m
v4.8.6
v6.12.0
v6.12.1
v8.9
v8.9.1
[34m[1mphpenv versions[0m
  system
  5.6
* 5.6.32 (set by /home/travis/.phpenv/version)
  7.0
  7.0.25
  7.1
  7.1.11
  hhvm
  hhvm-stable
[34m[1mcomposer --version[0m
Composer version 1.5.2 2017-09-11 16:59:25
[34m[1mPre-installed Ruby versions[0m
ruby-2.2.7
ruby-2.3.4
ruby-2.4.1
travis_fold:end:system_info[0K
W: The repository 'http://www.apache.org/dist/cassandra/debian 39x Release' does not have a Release file.
W: GPG error: http://dl.google.com/linux/chrome/deb stable InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 78BD65473CB3BD13
W: The repository 'http://dl.google.com/linux/chrome/deb stable InRelease' is not signed.
W: There is no public key available for the following key IDs:
78BD65473CB3BD13  
W: GPG error: http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 Release: The following signatures were invalid: KEYEXPIRED 1515625755
W: The repository 'http://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.4 Release' is not signed.
W: GPG error: https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 6B05F25D762E3157
W: The repository 'https://packagecloud.io/github/git-lfs/ubuntu trusty InRelease' is not signed.
W: There is no public key available for the following key IDs:
6B05F25D762E3157  
W: The repository 'https://packagecloud.io/basho/riak/ubuntu trusty Release' does not have a Release file.
W: The repository 'http://apt.postgresql.org/pub/repos/apt trusty-pgdg Release' does not have a Release file.
W: GPG error: https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu trusty InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY F6609E60DC62814E
W: The repository 'https://packagecloud.io/rabbitmq/rabbitmq-server/ubuntu trusty InRelease' is not signed.
W: There is no public key available for the following key IDs:
F6609E60DC62814E  
W: http://ppa.launchpad.net/couchdb/stable/ubuntu/dists/trusty/Release.gpg: Signature by key 15866BAFD9BCC4F3C1E0DFC7D69548E1C17EAB57 uses weak digest algorithm (SHA1)
E: Failed to fetch https://www.apache.org/dist/cassandra/debian/dists/39x/main/binary-amd64/Packages  gnutls_handshake() failed: Handshake failed
E: Failed to fetch https://www.apache.org/dist/cassandra/debian/dists/39x/main/binary-i386/Packages  gnutls_handshake() failed: Handshake failed
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/source/Sources  HttpError402
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/binary-amd64/Packages  HttpError402
E: Failed to fetch https://packagecloud.io/basho/riak/ubuntu/dists/trusty/main/binary-i386/Packages  HttpError402
E: Failed to fetch http://apt.postgresql.org/pub/repos/apt/dists/trusty-pgdg/main/binary-amd64/Packages  404  Not Found [IP: 217.196.149.55 80]
E: Failed to fetch http://apt.postgresql.org/pub/repos/apt/dists/trusty-pgdg/main/binary-i386/Packages  404  Not Found [IP: 217.196.149.55 80]
E: Some index files failed to download. They have been ignored, or old ones used instead.
sed: cannot rename /etc/hosts: Device or resource busy
sed: cannot rename /etc/hosts: Device or resource busy
$ jdk_switcher use oraclejdk8
Switching to Oracle JDK8 (java-8-oracle), JAVA_HOME will be set to /usr/lib/jvm/java-8-oracle
$ cd passed/crate/crate-jdbc
travis_fold:start:git.submodule[0Ktravis_time:start:09e6ede4[0K$ git submodule update --init --recursive

travis_time:end:09e6ede4:start=1644126811824992242,finish=1644126812079906073,duration=254913831[0Ktravis_fold:end:git.submodule[0K
[33;1mSetting environment variables from .travis.yml[0m
$ export CRATE_VERSION=0.56.4

$ export TERM=dumb
travis_fold:start:cache.1[0KSetting up build cache
$ export CASHER_DIR=$HOME/.casher
travis_time:start:0cf392be[0K
travis_time:end:0cf392be:start=1644126812906571298,finish=1644126812916789978,duration=10218680[0Ktravis_time:start:1dc2e5b7[0K/home/travis/.casher/bin/casher:213:in `cache_archive_name': undefined method `[]' for nil:NilClass (NoMethodError)
	from /home/travis/.casher/bin/casher:65:in `block in fetch'
	from /home/travis/.casher/bin/casher:64:in `each'
	from /home/travis/.casher/bin/casher:64:in `fetch'
	from /home/travis/.casher/bin/casher:53:in `block in run'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:88:in `block in timeout'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `block in catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:103:in `timeout'
	from /home/travis/.casher/bin/casher:53:in `run'
	from /home/travis/.casher/bin/casher:263:in `<main>'
[32;1mattempting to download cache archive[0m

travis_time:end:1dc2e5b7:start=1644126812929685311,finish=1644126813893783746,duration=964098435[0Ktravis_time:start:02934240[0K
travis_time:end:02934240:start=1644126813907291581,finish=1644126813920081774,duration=12790193[0Ktravis_time:start:08f0557a[0K[32;1madding /home/travis/.m2 to cache[0m

travis_time:end:08f0557a:start=1644126813934370124,finish=1644126814919060033,duration=984689909[0Ktravis_fold:end:cache.1[0K$ java -Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
java version "1.8.0_151"
Java(TM) SE Runtime Environment (build 1.8.0_151-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode)
$ javac -J-Xmx32m -version
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
javac 1.8.0_151
travis_fold:start:install[0Ktravis_time:start:0dc76ca0[0K$ JAVA_HOME=$(jdk_switcher home openjdk8) ./gradlew classes testClasses
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Starting a Gradle Daemon, 2 incompatible and 1 stopped Daemons could not be reused, use --status for details
:pg:preprocessJava
Preproces: upstream/pgjdbc/src/main/java -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/java
Preproces: upstream/pgjdbc/src/main/resources -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/resources
:pg:compileJava UP-TO-DATE
:pg:processResources UP-TO-DATE
:pg:classes UP-TO-DATE
:pg:jar UP-TO-DATE
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:compileTestJava UP-TO-DATE
:processTestResources NO-SOURCE
:testClasses UP-TO-DATE
:pg:compileTestJava NO-SOURCE
:pg:processTestResources NO-SOURCE
:pg:testClasses UP-TO-DATE

BUILD SUCCESSFUL in 12s
7 actionable tasks: 1 executed, 6 up-to-date

travis_time:end:0dc76ca0:start=1644126815219713369,finish=1644126828524343469,duration=13304630100[0Ktravis_fold:end:install[0Ktravis_time:start:1b09569c[0K$ ./gradlew test -s
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
Starting a Gradle Daemon, 2 incompatible and 2 stopped Daemons could not be reused, use --status for details
:pg:preprocessJava
Preproces: upstream/pgjdbc/src/main/java -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/java
Preproces: upstream/pgjdbc/src/main/resources -> /home/travis/build/passed/crate/crate-jdbc/pg/build/jcp/main/resources
:pg:compileJava UP-TO-DATE
:pg:processResources UP-TO-DATE
:pg:classes UP-TO-DATE
:pg:jar UP-TO-DATE
:compileJava UP-TO-DATE
:processResources UP-TO-DATE
:classes UP-TO-DATE
:compileTestJava UP-TO-DATE
:processTestResources NO-SOURCE
:testClasses UP-TO-DATE
:testPicked up _JAVA_OPTIONS: -Xmx2048m -Xms512m


io.crate.client.jdbc.integrationtests.CrateJDBCByPassSpecSettingTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-02-06 05:53:57,692][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-02-06 05:53:57,840][INFO ][node                     ] [Piz Lagrev] version[2.3.4], pid[2784], build[${build/NA]
[2022-02-06 05:53:57,841][INFO ][node                     ] [Piz Lagrev] initializing ...
[2022-02-06 05:53:58,132][INFO ][io.crate.plugin          ] [Piz Lagrev] plugins loaded: [crate-sigar] 
[2022-02-06 05:53:59,061][INFO ][plugins                  ] [Piz Lagrev] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-02-06 05:53:59,084][INFO ][env                      ] [Piz Lagrev] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.5tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-02-06 05:53:59,084][INFO ][env                      ] [Piz Lagrev] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-02-06 05:53:59,084][WARN ][env                      ] [Piz Lagrev] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-02-06 05:53:59,269][INFO ][http                     ] [Piz Lagrev] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-02-06 05:53:59,278][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_606855e3-e97f-47ff-9a2b-90839050bae3/plugins/elasticsearch-repository-hdfs/
[2022-02-06 05:53:59,330][INFO ][io.crate.module          ] [Piz Lagrev] configuring crate. version: 0.56.4
[2022-02-06 05:53:59,507][INFO ][io.crate.module          ] [Piz Lagrev] configuring crate. version: 0.56.4
[2022-02-06 05:54:00,622][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5455]
[2022-02-06 05:54:00,622][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-02-06 05:54:01,830][INFO ][io.crate.rest            ] [Piz Lagrev] Elasticsearch HTTP REST API not enabled
[2022-02-06 05:54:01,889][INFO ][node                     ] [Piz Lagrev] initialized
[2022-02-06 05:54:01,889][INFO ][node                     ] [Piz Lagrev] starting ...
[2022-02-06 05:54:02,049][INFO ][io.crate.blob.BlobService] [Piz Lagrev] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-02-06 05:54:02,159][INFO ][http                     ] [Piz Lagrev] publish_address {127.0.0.1:4519}, bound_addresses {127.0.0.1:4519}
[2022-02-06 05:54:02,260][INFO ][transport                ] [Piz Lagrev] publish_address {127.0.0.1:4365}, bound_addresses {127.0.0.1:4365}
[2022-02-06 05:54:02,268][INFO ][discovery                ] [Piz Lagrev] TestingCluster/M9yhZBjaTVCr1qXj8SOvBA
    Stopping crate server process...
[2022-02-06 05:54:03,127][INFO ][node                     ] [Piz Lagrev] stopping ...
[2022-02-06 05:54:03,193][INFO ][node                     ] [Piz Lagrev] stopped
[2022-02-06 05:54:03,193][INFO ][node                     ] [Piz Lagrev] closing ...
[2022-02-06 05:54:03,201][INFO ][node                     ] [Piz Lagrev] closed

io.crate.client.jdbc.integrationtests.CrateJDBCConnectionTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-02-06 05:54:04,483][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-02-06 05:54:04,626][INFO ][node                     ] [T√™te des Lauzi√®res] version[2.3.4], pid[3142], build[${build/NA]
[2022-02-06 05:54:04,626][INFO ][node                     ] [T√™te des Lauzi√®res] initializing ...
[2022-02-06 05:54:04,904][INFO ][io.crate.plugin          ] [T√™te des Lauzi√®res] plugins loaded: [crate-sigar] 
[2022-02-06 05:54:05,827][INFO ][plugins                  ] [T√™te des Lauzi√®res] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-02-06 05:54:05,849][INFO ][env                      ] [T√™te des Lauzi√®res] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.5tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-02-06 05:54:05,849][INFO ][env                      ] [T√™te des Lauzi√®res] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-02-06 05:54:05,849][WARN ][env                      ] [T√™te des Lauzi√®res] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-02-06 05:54:06,033][INFO ][http                     ] [T√™te des Lauzi√®res] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-02-06 05:54:06,043][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_5eea128c-64fc-4d3b-82dc-4f0eb4f29e52/plugins/elasticsearch-repository-hdfs/
[2022-02-06 05:54:06,103][INFO ][io.crate.module          ] [T√™te des Lauzi√®res] configuring crate. version: 0.56.4
[2022-02-06 05:54:06,298][INFO ][io.crate.module          ] [T√™te des Lauzi√®res] configuring crate. version: 0.56.4
[2022-02-06 05:54:07,441][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5474]
[2022-02-06 05:54:07,441][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-02-06 05:54:08,541][INFO ][io.crate.rest            ] [T√™te des Lauzi√®res] Elasticsearch HTTP REST API not enabled
[2022-02-06 05:54:08,581][INFO ][node                     ] [T√™te des Lauzi√®res] initialized
[2022-02-06 05:54:08,582][INFO ][node                     ] [T√™te des Lauzi√®res] starting ...
[2022-02-06 05:54:08,717][INFO ][io.crate.blob.BlobService] [T√™te des Lauzi√®res] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-02-06 05:54:08,825][INFO ][http                     ] [T√™te des Lauzi√®res] publish_address {127.0.0.1:4506}, bound_addresses {127.0.0.1:4506}
[2022-02-06 05:54:08,894][INFO ][transport                ] [T√™te des Lauzi√®res] publish_address {127.0.0.1:4320}, bound_addresses {127.0.0.1:4320}
[2022-02-06 05:54:08,900][INFO ][discovery                ] [T√™te des Lauzi√®res] TestingCluster/U58ir1xWRS2pvjcv7ByBgQ
[2022-02-06 05:54:09,680][DEBUG][action.admin.indices.create] [T√™te des Lauzi√®res] no known master node, scheduling a retry
[2022-02-06 05:54:11,935][INFO ][cluster.service          ] [T√™te des Lauzi√®res] new_master {T√™te des Lauzi√®res}{U58ir1xWRS2pvjcv7ByBgQ}{127.0.0.1}{127.0.0.1:4320}{info.extended.type=sigar, http_address=127.0.0.1:4506}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-02-06 05:54:11,940][INFO ][node                     ] [T√™te des Lauzi√®res] started
[2022-02-06 05:54:11,999][INFO ][gateway                  ] [T√™te des Lauzi√®res] recovered [0] indices into cluster_state
[2022-02-06 05:54:12,217][INFO ][cluster.metadata         ] [T√™te des Lauzi√®res] [test] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-02-06 05:54:12,587][INFO ][cluster.routing.allocation] [T√™te des Lauzi√®res] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test][0]] ...]).
[2022-02-06 05:54:15,810][DEBUG][action.bulk              ] create new coordinator for node U58ir1xWRS2pvjcv7ByBgQ and shard [test][0]
    Stopping crate server process...
[2022-02-06 05:54:16,770][INFO ][node                     ] [T√™te des Lauzi√®res] stopping ...
[2022-02-06 05:54:17,023][INFO ][node                     ] [T√™te des Lauzi√®res] stopped
[2022-02-06 05:54:17,023][INFO ][node                     ] [T√™te des Lauzi√®res] closing ...
[2022-02-06 05:54:17,033][INFO ][node                     ] [T√™te des Lauzi√®res] closed

io.crate.client.jdbc.integrationtests.CrateJDBCDriverTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-02-06 05:54:18,291][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-02-06 05:54:18,440][INFO ][node                     ] [Roc Cornafion] version[2.3.4], pid[3533], build[${build/NA]
[2022-02-06 05:54:18,440][INFO ][node                     ] [Roc Cornafion] initializing ...
[2022-02-06 05:54:18,725][INFO ][io.crate.plugin          ] [Roc Cornafion] plugins loaded: [crate-sigar] 
[2022-02-06 05:54:19,762][INFO ][plugins                  ] [Roc Cornafion] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-02-06 05:54:19,779][INFO ][env                      ] [Roc Cornafion] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.5tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-02-06 05:54:19,779][INFO ][env                      ] [Roc Cornafion] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-02-06 05:54:19,779][WARN ][env                      ] [Roc Cornafion] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-02-06 05:54:19,966][INFO ][http                     ] [Roc Cornafion] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-02-06 05:54:19,978][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_056b8c2b-f541-4c14-ba8d-7e3b95ddbef9/plugins/elasticsearch-repository-hdfs/
[2022-02-06 05:54:20,037][INFO ][io.crate.module          ] [Roc Cornafion] configuring crate. version: 0.56.4
[2022-02-06 05:54:20,198][INFO ][io.crate.module          ] [Roc Cornafion] configuring crate. version: 0.56.4
[2022-02-06 05:54:21,281][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5442]
[2022-02-06 05:54:21,281][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-02-06 05:54:22,505][INFO ][io.crate.rest            ] [Roc Cornafion] Elasticsearch HTTP REST API not enabled
[2022-02-06 05:54:22,559][INFO ][node                     ] [Roc Cornafion] initialized
[2022-02-06 05:54:22,559][INFO ][node                     ] [Roc Cornafion] starting ...
[2022-02-06 05:54:22,731][INFO ][io.crate.blob.BlobService] [Roc Cornafion] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-02-06 05:54:22,843][INFO ][http                     ] [Roc Cornafion] publish_address {127.0.0.1:4594}, bound_addresses {127.0.0.1:4594}
[2022-02-06 05:54:22,951][INFO ][transport                ] [Roc Cornafion] publish_address {127.0.0.1:4292}, bound_addresses {127.0.0.1:4292}
[2022-02-06 05:54:22,957][INFO ][discovery                ] [Roc Cornafion] TestingCluster/_lfcjHbbT_u5-LQh1xmreA
    Stopping crate server process...
[2022-02-06 05:54:23,497][INFO ][node                     ] [Roc Cornafion] stopping ...
[2022-02-06 05:54:23,559][INFO ][node                     ] [Roc Cornafion] stopped
[2022-02-06 05:54:23,559][INFO ][node                     ] [Roc Cornafion] closing ...
[2022-02-06 05:54:23,565][INFO ][node                     ] [Roc Cornafion] closed

io.crate.client.jdbc.integrationtests.CrateJDBCFetchSizeIntegrationTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-02-06 05:54:24,715][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-02-06 05:54:24,854][INFO ][node                     ] [Last√¨a de Fram√≥nt] version[2.3.4], pid[3890], build[${build/NA]
[2022-02-06 05:54:24,854][INFO ][node                     ] [Last√¨a de Fram√≥nt] initializing ...
[2022-02-06 05:54:25,125][INFO ][io.crate.plugin          ] [Last√¨a de Fram√≥nt] plugins loaded: [crate-sigar] 
[2022-02-06 05:54:25,974][INFO ][plugins                  ] [Last√¨a de Fram√≥nt] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-02-06 05:54:25,995][INFO ][env                      ] [Last√¨a de Fram√≥nt] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.5tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-02-06 05:54:25,995][INFO ][env                      ] [Last√¨a de Fram√≥nt] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-02-06 05:54:25,995][WARN ][env                      ] [Last√¨a de Fram√≥nt] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-02-06 05:54:26,191][INFO ][http                     ] [Last√¨a de Fram√≥nt] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-02-06 05:54:26,201][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_35e7772b-6886-4ed4-896a-b36d6c224bbe/plugins/elasticsearch-repository-hdfs/
[2022-02-06 05:54:26,255][INFO ][io.crate.module          ] [Last√¨a de Fram√≥nt] configuring crate. version: 0.56.4
[2022-02-06 05:54:26,441][INFO ][io.crate.module          ] [Last√¨a de Fram√≥nt] configuring crate. version: 0.56.4
[2022-02-06 05:54:27,659][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5486]
[2022-02-06 05:54:27,659][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-02-06 05:54:28,876][INFO ][io.crate.rest            ] [Last√¨a de Fram√≥nt] Elasticsearch HTTP REST API not enabled
[2022-02-06 05:54:28,920][INFO ][node                     ] [Last√¨a de Fram√≥nt] initialized
[2022-02-06 05:54:28,920][INFO ][node                     ] [Last√¨a de Fram√≥nt] starting ...
[2022-02-06 05:54:29,075][INFO ][io.crate.blob.BlobService] [Last√¨a de Fram√≥nt] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-02-06 05:54:29,202][INFO ][http                     ] [Last√¨a de Fram√≥nt] publish_address {127.0.0.1:4535}, bound_addresses {127.0.0.1:4535}
[2022-02-06 05:54:29,300][INFO ][transport                ] [Last√¨a de Fram√≥nt] publish_address {127.0.0.1:4314}, bound_addresses {127.0.0.1:4314}
[2022-02-06 05:54:29,307][INFO ][discovery                ] [Last√¨a de Fram√≥nt] TestingCluster/JQ6PuwDGTP-el5P4hqlUUg
    Stopping crate server process...
[2022-02-06 05:54:29,989][INFO ][node                     ] [Last√¨a de Fram√≥nt] stopping ...
[2022-02-06 05:54:30,824][WARN ][discovery.zen.ping.unicast] [Last√¨a de Fram√≥nt] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:4314}]
SendRequestTransportException[[Last√¨a de Fram√≥nt][127.0.0.1:4314][internal:discovery/zen/unicast]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:336)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:316)
	... 7 more
[2022-02-06 05:54:30,824][WARN ][discovery.zen.ping.unicast] [Last√¨a de Fram√≥nt] failed to send ping to [{Last√¨a de Fram√≥nt}{JQ6PuwDGTP-el5P4hqlUUg}{127.0.0.1}{127.0.0.1:4314}{info.extended.type=sigar, http_address=127.0.0.1:4535}]
SendRequestTransportException[[Last√¨a de Fram√≥nt][127.0.0.1:4314][internal:discovery/zen/unicast]]; nested: TransportException[TransportService is closed stopped can't send request];
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:336)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPingRequestToNode(UnicastZenPing.java:440)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:426)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing$2.doRun(UnicastZenPing.java:249)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: TransportException[TransportService is closed stopped can't send request]
	at org.elasticsearch.transport.TransportService.sendRequest(TransportService.java:316)
	... 7 more
[2022-02-06 05:54:31,175][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:577)
	at org.jboss.netty.channel.Channels.write(Channels.java:704)
	at org.jboss.netty.channel.Channels.write(Channels.java:671)
	at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:348)
	at io.crate.protocols.postgres.Messages.sendErrorResponse(Messages.java:231)
	at io.crate.protocols.postgres.ResultSetReceiver.fail(ResultSetReceiver.java:79)
	at io.crate.protocols.postgres.SimplePortal$ResultReceiverRetryWrapper.fail(SimplePortal.java:273)
	at io.crate.action.sql.RowReceiverToResultReceiver.fail(RowReceiverToResultReceiver.java:67)
	at io.crate.executor.transport.executionphases.InterceptingRowReceiver$1.onFailure(InterceptingRowReceiver.java:133)
	at io.crate.executor.MultiActionListener.countdown(MultiActionListener.java:68)
	at io.crate.executor.MultiActionListener.onFailure(MultiActionListener.java:59)
	at io.crate.executor.transport.DefaultTransportResponseHandler.handleException(DefaultTransportResponseHandler.java:62)
	at org.elasticsearch.transport.TransportService$3.doRun(TransportService.java:349)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-02-06 05:54:31,176][INFO ][node                     ] [Last√¨a de Fram√≥nt] stopped
[2022-02-06 05:54:31,178][WARN ][netty.channel.DefaultChannelPipeline] An exception was thrown by an exception handler.
java.util.concurrent.RejectedExecutionException: Worker has already been shutdown
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.registerTask(AbstractNioSelector.java:120)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:72)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.executeInIoThread(AbstractNioWorker.java:56)
	at org.jboss.netty.channel.socket.nio.NioWorker.executeInIoThread(NioWorker.java:36)
	at org.jboss.netty.channel.socket.nio.AbstractNioChannelSink.execute(AbstractNioChannelSink.java:34)
	at org.jboss.netty.channel.DefaultChannelPipeline.execute(DefaultChannelPipeline.java:636)
	at org.jboss.netty.channel.Channels.fireExceptionCaughtLater(Channels.java:496)
	at org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:46)
	at org.jboss.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:577)
	at org.jboss.netty.channel.Channels.write(Channels.java:704)
	at org.jboss.netty.channel.Channels.write(Channels.java:671)
	at org.jboss.netty.channel.AbstractChannel.write(AbstractChannel.java:348)
	at io.crate.protocols.postgres.Messages.sendReadyForQuery(Messages.java:140)
	at io.crate.protocols.postgres.ConnectionContext$ReadyForQueryListener.onFailure(ConnectionContext.java:222)
	at io.crate.concurrent.CompletionMultiListener.onFailure(CompletionMultiListener.java:63)
	at io.crate.protocols.postgres.ResultSetReceiver.fail(ResultSetReceiver.java:80)
	at io.crate.protocols.postgres.SimplePortal$ResultReceiverRetryWrapper.fail(SimplePortal.java:273)
	at io.crate.action.sql.RowReceiverToResultReceiver.fail(RowReceiverToResultReceiver.java:67)
	at io.crate.executor.transport.executionphases.InterceptingRowReceiver$1.onFailure(InterceptingRowReceiver.java:133)
	at io.crate.executor.MultiActionListener.countdown(MultiActionListener.java:68)
	at io.crate.executor.MultiActionListener.onFailure(MultiActionListener.java:59)
	at io.crate.executor.transport.DefaultTransportResponseHandler.handleException(DefaultTransportResponseHandler.java:62)
	at org.elasticsearch.transport.TransportService$3.doRun(TransportService.java:349)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-02-06 05:54:31,178][INFO ][node                     ] [Last√¨a de Fram√≥nt] closing ...
[2022-02-06 05:54:31,186][INFO ][node                     ] [Last√¨a de Fram√≥nt] closed

io.crate.client.jdbc.integrationtests.CrateJDBCMetaDataIntegrationTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-02-06 05:54:32,503][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-02-06 05:54:32,644][INFO ][node                     ] [Aouille Tseuque] version[2.3.4], pid[4251], build[${build/NA]
[2022-02-06 05:54:32,644][INFO ][node                     ] [Aouille Tseuque] initializing ...
[2022-02-06 05:54:32,922][INFO ][io.crate.plugin          ] [Aouille Tseuque] plugins loaded: [crate-sigar] 
[2022-02-06 05:54:33,790][INFO ][plugins                  ] [Aouille Tseuque] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-02-06 05:54:33,809][INFO ][env                      ] [Aouille Tseuque] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.5tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-02-06 05:54:33,809][INFO ][env                      ] [Aouille Tseuque] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-02-06 05:54:33,809][WARN ][env                      ] [Aouille Tseuque] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-02-06 05:54:33,975][INFO ][http                     ] [Aouille Tseuque] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-02-06 05:54:33,984][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_4ecdeac9-848c-4a29-9700-c32d9f67c11f/plugins/elasticsearch-repository-hdfs/
[2022-02-06 05:54:34,030][INFO ][io.crate.module          ] [Aouille Tseuque] configuring crate. version: 0.56.4
[2022-02-06 05:54:34,189][INFO ][io.crate.module          ] [Aouille Tseuque] configuring crate. version: 0.56.4
[2022-02-06 05:54:35,436][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5462]
[2022-02-06 05:54:35,437][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-02-06 05:54:36,559][INFO ][io.crate.rest            ] [Aouille Tseuque] Elasticsearch HTTP REST API not enabled
[2022-02-06 05:54:36,603][INFO ][node                     ] [Aouille Tseuque] initialized
[2022-02-06 05:54:36,603][INFO ][node                     ] [Aouille Tseuque] starting ...
[2022-02-06 05:54:36,754][INFO ][io.crate.blob.BlobService] [Aouille Tseuque] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-02-06 05:54:36,870][INFO ][http                     ] [Aouille Tseuque] publish_address {127.0.0.1:4519}, bound_addresses {127.0.0.1:4519}
[2022-02-06 05:54:36,997][INFO ][transport                ] [Aouille Tseuque] publish_address {127.0.0.1:4203}, bound_addresses {127.0.0.1:4203}
[2022-02-06 05:54:37,004][INFO ][discovery                ] [Aouille Tseuque] TestingCluster/iExl2J5nTDim9vMBFVs33Q
[2022-02-06 05:54:37,720][DEBUG][action.admin.indices.create] [Aouille Tseuque] no known master node, scheduling a retry
[2022-02-06 05:54:40,039][INFO ][cluster.service          ] [Aouille Tseuque] new_master {Aouille Tseuque}{iExl2J5nTDim9vMBFVs33Q}{127.0.0.1}{127.0.0.1:4203}{info.extended.type=sigar, http_address=127.0.0.1:4519}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-02-06 05:54:40,044][INFO ][node                     ] [Aouille Tseuque] started
[2022-02-06 05:54:40,162][INFO ][gateway                  ] [Aouille Tseuque] recovered [0] indices into cluster_state
[2022-02-06 05:54:40,340][INFO ][cluster.metadata         ] [Aouille Tseuque] [test.cluster] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-02-06 05:54:40,925][INFO ][cluster.routing.allocation] [Aouille Tseuque] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[test.cluster][1], [test.cluster][3], [test.cluster][2], [test.cluster][0]] ...]).
[2022-02-06 05:54:40,995][INFO ][cluster.metadata         ] [Aouille Tseuque] [names] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-02-06 05:54:41,127][INFO ][cluster.routing.allocation] [Aouille Tseuque] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[names][2], [names][1], [names][0], [names][3]] ...]).
[2022-02-06 05:54:41,151][INFO ][cluster.metadata         ] [Aouille Tseuque] [my_schema.names] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-02-06 05:54:41,354][INFO ][cluster.routing.allocation] [Aouille Tseuque] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[my_schema.names][2], [my_schema.names][0], [my_schema.names][3], [my_schema.names][1]] ...]).
[2022-02-06 05:54:41,704][INFO ][cluster.metadata         ] [Aouille Tseuque] [t_multi_pks] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-02-06 05:54:41,783][INFO ][cluster.routing.allocation] [Aouille Tseuque] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[t_multi_pks][0], [t_multi_pks][0]] ...]).
    Stopping crate server process...
[2022-02-06 05:54:41,894][INFO ][node                     ] [Aouille Tseuque] stopping ...
[2022-02-06 05:54:41,995][INFO ][node                     ] [Aouille Tseuque] stopped
[2022-02-06 05:54:41,995][INFO ][node                     ] [Aouille Tseuque] closing ...
[2022-02-06 05:54:42,005][INFO ][node                     ] [Aouille Tseuque] closed

io.crate.client.jdbc.integrationtests.CrateJDBCTypesTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-02-06 05:54:43,243][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-02-06 05:54:43,376][INFO ][node                     ] [Monte Scinauz] version[2.3.4], pid[4654], build[${build/NA]
[2022-02-06 05:54:43,376][INFO ][node                     ] [Monte Scinauz] initializing ...
[2022-02-06 05:54:43,595][INFO ][io.crate.plugin          ] [Monte Scinauz] plugins loaded: [crate-sigar] 
[2022-02-06 05:54:44,492][INFO ][plugins                  ] [Monte Scinauz] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-02-06 05:54:44,514][INFO ][env                      ] [Monte Scinauz] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.5tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-02-06 05:54:44,514][INFO ][env                      ] [Monte Scinauz] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-02-06 05:54:44,514][WARN ][env                      ] [Monte Scinauz] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-02-06 05:54:44,720][INFO ][http                     ] [Monte Scinauz] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-02-06 05:54:44,729][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_53a74790-0e4f-4394-bebb-b83a590be7b8/plugins/elasticsearch-repository-hdfs/
[2022-02-06 05:54:44,797][INFO ][io.crate.module          ] [Monte Scinauz] configuring crate. version: 0.56.4
[2022-02-06 05:54:44,981][INFO ][io.crate.module          ] [Monte Scinauz] configuring crate. version: 0.56.4
[2022-02-06 05:54:46,197][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5472]
[2022-02-06 05:54:46,197][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-02-06 05:54:47,453][INFO ][io.crate.rest            ] [Monte Scinauz] Elasticsearch HTTP REST API not enabled
[2022-02-06 05:54:47,498][INFO ][node                     ] [Monte Scinauz] initialized
[2022-02-06 05:54:47,498][INFO ][node                     ] [Monte Scinauz] starting ...
[2022-02-06 05:54:47,645][INFO ][io.crate.blob.BlobService] [Monte Scinauz] BlobService.doStart() io.crate.blob.BlobService@eebc0db
[2022-02-06 05:54:47,755][INFO ][http                     ] [Monte Scinauz] publish_address {127.0.0.1:4551}, bound_addresses {127.0.0.1:4551}
[2022-02-06 05:54:47,836][INFO ][transport                ] [Monte Scinauz] publish_address {127.0.0.1:4311}, bound_addresses {127.0.0.1:4311}
[2022-02-06 05:54:47,843][INFO ][discovery                ] [Monte Scinauz] TestingCluster/s9eFtASvTIy_VZKNXpIxwg
[2022-02-06 05:54:48,486][DEBUG][action.admin.indices.create] [Monte Scinauz] no known master node, scheduling a retry
[2022-02-06 05:54:50,876][INFO ][cluster.service          ] [Monte Scinauz] new_master {Monte Scinauz}{s9eFtASvTIy_VZKNXpIxwg}{127.0.0.1}{127.0.0.1:4311}{info.extended.type=sigar, http_address=127.0.0.1:4551}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2022-02-06 05:54:50,881][INFO ][node                     ] [Monte Scinauz] started
[2022-02-06 05:54:50,997][INFO ][gateway                  ] [Monte Scinauz] recovered [0] indices into cluster_state
[2022-02-06 05:54:51,210][INFO ][cluster.metadata         ] [Monte Scinauz] [test] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-02-06 05:54:51,509][INFO ][cluster.routing.allocation] [Monte Scinauz] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[test][0]] ...]).
[2022-02-06 05:54:52,382][INFO ][cluster.metadata         ] [Monte Scinauz] [arraytest] creating index, cause [api], templates [], shards [1]/[0], mappings [default]
[2022-02-06 05:54:52,662][INFO ][cluster.routing.allocation] [Monte Scinauz] Cluster health status changed from [RED] to [GREEN] (reason: [shards started [[arraytest][0]] ...]).
[2022-02-06 05:54:52,798][INFO ][cluster.metadata         ] [Monte Scinauz] [arraytest] update_mapping [default]
[2022-02-06 05:54:53,319][INFO ][cluster.metadata         ] [Monte Scinauz] [test_obj] creating index, cause [api], templates [], shards [4]/[1], mappings [default]
[2022-02-06 05:54:53,726][INFO ][cluster.routing.allocation] [Monte Scinauz] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[test_obj][0], [test_obj][3], [test_obj][2], [test_obj][1]] ...]).
    Stopping crate server process...
[2022-02-06 05:54:54,425][INFO ][node                     ] [Monte Scinauz] stopping ...
[2022-02-06 05:54:54,637][INFO ][node                     ] [Monte Scinauz] stopped
[2022-02-06 05:54:54,637][INFO ][node                     ] [Monte Scinauz] closing ...
[2022-02-06 05:54:54,651][INFO ][node                     ] [Monte Scinauz] closed

io.crate.client.jdbc.integrationtests.CrateJDBCUnsupportedFeaturesTest STANDARD_OUT
    No need to download crate. Already downloaded VERSION[0.56.4] to: /tmp/crate.testing/downloads/crate-0.56.4.tar.gz
    Starting crate server process...
Picked up _JAVA_OPTIONS: -Xmx2048m -Xms512m
[2022-02-06 05:54:55,935][WARN ][bootstrap                ] unable to install syscall filter: seccomp unavailable: your kernel is buggy and you should upgrade
[2022-02-06 05:54:56,082][INFO ][node                     ] [K√∂nigspitze] version[2.3.4], pid[5106], build[${build/NA]
[2022-02-06 05:54:56,083][INFO ][node                     ] [K√∂nigspitze] initializing ...
[2022-02-06 05:54:56,322][INFO ][io.crate.plugin          ] [K√∂nigspitze] plugins loaded: [crate-sigar] 
[2022-02-06 05:54:57,150][INFO ][plugins                  ] [K√∂nigspitze] modules [], plugins [cloud-aws, blob, discovery-multicast, udc, crate-admin-ui, repository-hdfs, discovery-srv, admin-ui, crate, crate-core, crate-azure-discovery], sites [crate-admin-ui]
[2022-02-06 05:54:57,178][INFO ][env                      ] [K√∂nigspitze] using [1] data paths, mounts [[/ (overlay)]], net usable_space [84.5tb], net total_space [90.9tb], spins? [possibly], types [overlay]
[2022-02-06 05:54:57,178][INFO ][env                      ] [K√∂nigspitze] heap size [1.9gb], compressed ordinary object pointers [true]
[2022-02-06 05:54:57,178][WARN ][env                      ] [K√∂nigspitze] max file descriptors [30000] for elasticsearch process likely too low, consider increasing to at least [65536]
[2022-02-06 05:54:57,364][INFO ][http                     ] [K√∂nigspitze] Using [io.crate.http.netty.CrateNettyHttpServerTransport] as http transport, overridden by [crate]
[2022-02-06 05:54:57,371][INFO ][plugin.hadoop.hdfs       ] Loaded Hadoop [Unknown] libraries from file:/tmp/crate.testing/working/crate-0.56.4_03b28b3e-e16c-43ea-87d2-0d074744e772/plugins/elasticsearch-repository-hdfs/
[2022-02-06 05:54:57,414][INFO ][io.crate.module          ] [K√∂nigspitze] configuring crate. version: 0.56.4
[2022-02-06 05:54:57,563][INFO ][io.crate.module          ] [K√∂nigspitze] configuring crate. version: 0.56.4
[2022-02-06 05:54:58,770][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.port] from [5432-5532] to [5490]
[2022-02-06 05:54:58,771][INFO ][io.crate.operation.reference.sys.cluster.ClusterSettingsExpression$ApplySettings] updating [psql.enabled] from [false] to [true]
[2022-02-06 05:54:59,978][INFO ][io.crate.rest            ] [K√∂nigspitze] Elasticsearch HTTP REST API not enabled
[2022-02-06 05:55:00,028][INFO ][node                     ] [K√∂nigspitze] initialized
[2022-02-06 05:55:00,029][INFO ][node                     ] [K√∂nigspitze] starting ...
[2022-02-06 05:55:00,192][INFO ][io.crate.blob.BlobService] [K√∂nigspitze] BlobService.doStart() io.crate.blob.BlobService@4627dfda
[2022-02-06 05:55:00,388][INFO ][http                     ] [K√∂nigspitze] publish_address {127.0.0.1:4501}, bound_addresses {127.0.0.1:4501}
[2022-02-06 05:55:00,526][INFO ][transport                ] [K√∂nigspitze] publish_address {127.0.0.1:4207}, bound_addresses {127.0.0.1:4207}
[2022-02-06 05:55:00,533][INFO ][discovery                ] [K√∂nigspitze] TestingCluster/w_02soeIRxGa0_xgD4hpZA
    Stopping crate server process...
[2022-02-06 05:55:01,084][INFO ][node                     ] [K√∂nigspitze] stopping ...
[2022-02-06 05:55:01,157][INFO ][node                     ] [K√∂nigspitze] stopped
[2022-02-06 05:55:01,157][INFO ][node                     ] [K√∂nigspitze] closing ...
[2022-02-06 05:55:01,163][INFO ][node                     ] [K√∂nigspitze] closed
:pg:compileTestJava NO-SOURCE
:pg:processTestResources NO-SOURCE
:pg:testClasses UP-TO-DATE
:pg:test SKIPPED

BUILD SUCCESSFUL in 1m 12s
8 actionable tasks: 2 executed, 6 up-to-date

travis_time:end:1b09569c:start=1644126828537397998,finish=1644126901966366756,duration=73428968758[0K
[32;1mThe command "./gradlew test -s" exited with 0.[0m
travis_fold:start:cache.2[0Kstore build cache
travis_time:start:0009ea26[0K
travis_time:end:0009ea26:start=1644126901978033512,finish=1644126901987636126,duration=9602614[0Ktravis_time:start:093f29f4[0K/home/travis/.casher/bin/casher:190: warning: Insecure world writable dir /usr/local/clang-5.0.0/bin in PATH, mode 040777
[32;1mchanges detected, packing new archive[0m
/home/travis/.casher/bin/casher:213:in `cache_archive_name': undefined method `[]' for nil:NilClass (NoMethodError)
	from /home/travis/.casher/bin/casher:143:in `push'
	from /home/travis/.casher/bin/casher:53:in `block in run'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:88:in `block in timeout'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `block in catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:32:in `catch'
	from /home/travis/.rvm/rubies/ruby-2.2.7/lib/ruby/2.2.0/timeout.rb:103:in `timeout'
	from /home/travis/.casher/bin/casher:53:in `run'
	from /home/travis/.casher/bin/casher:263:in `<main>'

travis_time:end:093f29f4:start=1644126902000912476,finish=1644126903930289537,duration=1929377061[0Ktravis_fold:end:cache.2[0K
Done. Your build exited with 0.
